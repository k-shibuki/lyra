# ADR-0002: Thinking-Working Separation

## Date
2025-11-01

## Context

AIを活用した調査支援ツールには大きく2つのアプローチがある：

1. **単一AIモデルで完結**: 1つの高性能モデルが調査計画から実行まで担当
2. **分離アーキテクチャ**: 思考（計画・判断）と作業（実行）を分離

単一モデルアプローチの問題点：

| 問題 | 詳細 |
|------|------|
| コスト | GPT-4/Claudeクラスの常時使用は高コスト |
| レイテンシ | 大規模モデルは応答が遅い |
| ローカル実行困難 | 70B+モデルは一般的なGPUで動作しない |

一方、ローカルの小型モデル（3B-7B）は：
- 抽出・分類などの機械的タスクは高精度で実行可能
- 複雑な推論・計画立案は苦手

## Decision

**「思考」と「作業」を明確に分離し、それぞれに最適なコンポーネントを割り当てる。**

### アーキテクチャ

```
┌─────────────────────────────────────────────────────────────┐
│  MCP Client (Claude Desktop / Cline / etc.)                 │
│  ─────────────────────────────────────────────────────────  │
│  • 調査計画の策定                                            │
│  • 探索戦略の決定                                            │
│  • 結果の解釈・統合                                          │
│  • ユーザーとの対話                                          │
└─────────────────────────────────────────────────────────────┘
                              │ MCP Protocol
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  Lyra (MCP Server)                                          │
│  ─────────────────────────────────────────────────────────  │
│  • Webクローリング実行                                       │
│  • テキスト抽出・構造化                                      │
│  • NLI判定（SUPPORTS/REFUTES/NEUTRAL）                      │
│  • データ永続化                                              │
└─────────────────────────────────────────────────────────────┘
```

### 責任マトリクス

**重要**: 検索クエリの「設計」は例外なくMCPクライアントが行う。Lyraが「候補を提案」することはない。

| 責任領域 | MCPクライアント（思考） | Lyra（作業） |
|---------|------------------------|--------------|
| 問いの分解 | ✅ 検索クエリの設計・優先度決定 | ❌ 設計には関与しない |
| クエリ生成 | ✅ すべてのクエリの設計・指定 | 機械的展開のみ（同義語・ミラークエリ） |
| 探索計画 | ✅ 計画の立案・決定 | 計画の実行・進捗報告 |
| 探索制御 | ✅ 次のアクション判断 | メトリクス計算と報告のみ |
| 反証探索 | ✅ 反証クエリの設計・指定 | 機械パターン適用（接尾辞付与等） |
| 停止判断 | ✅ 探索の終了指示 | 停止条件充足の報告 |
| レポート構成 | ✅ 論理構成・執筆判断 | 素材（断片・引用）の提供 |

### Lyraの処理範囲

Lyraは**MCPクライアントの指示に基づいて**以下を実行する（指示なしに探索を進めない）：

**実行すること**:
- 機械的展開: 指定クエリに対する同義語展開、言語横断ミラークエリ、演算子付与
- 取得・抽出パイプライン: 検索→取得→抽出→ランキング→NLI
- メトリクス計算: 収穫率、新規性、充足度、重複率
- 異常ハンドリング: CAPTCHA/ブロック検知、認証キューへの追加

**実行しないこと**:
- クエリの設計・候補提案
- 探索方針の決定
- 「次に何をすべきか」の推奨

### 対話フロー

探索はMCPクライアント主導のループで進行する：

```
1. create_task(query)
   └─ Lyra: タスク作成、task_id返却

2. MCPクライアント: クエリを設計（この判断はMCPクライアントのみ）

3. search(task_id, query)
   └─ Lyra: パイプライン実行、結果サマリ返却

4. get_status(task_id)
   └─ Lyra: メトリクスのみ返却（推奨なし）
     - クエリ状態（充足/部分充足/未充足）
     - 新規性スコア推移
     - 残り予算

5. MCPクライアント: 状況評価、次クエリ設計（3-4を繰り返す）

6. search(task_id, query, refute=true)
   └─ Lyra: 反証モードで実行

7. stop_task(task_id)
   └─ Lyra: 最終状態をDB記録

8. get_materials(task_id)
   └─ Lyra: 素材提供（主張、断片、グラフ）
   └─ MCPクライアント: レポート構成・執筆
```

### 具体例

```
ユーザー: 「気候変動が農業生産性に与える影響を調べて」

MCPクライアント（思考）:
  1. 「climate change agriculture productivity」で検索を指示
  2. get_statusでメトリクス確認、主要論文を特定
  3. 追加クエリ「crop yield climate impact」を設計・指示
  4. 反証クエリ「climate agriculture productivity criticism」を指示
  5. 収集したエビデンスを統合してレポート作成

Lyra（作業）:
  1. 検索クエリを実行、ページ取得
  2. テキスト抽出、NLI判定
  3. メトリクス（収穫率、新規性）を報告
  4. 最終素材を提供
```

## Consequences

### Positive
- **コスト最適化**: 高コストモデルは思考のみ、作業はローカル
- **品質担保**: 各コンポーネントが得意なタスクに集中
- **柔軟性**: MCPクライアントを自由に選択可能
- **ローカル実行**: ADR-0001のZero OpEx原則と整合

### Negative
- **クライアント依存**: MCPクライアントの品質に全体が依存
- **通信オーバーヘッド**: MCP経由のやり取りが発生
- **設計複雑性**: 責務分離の境界設計が必要

## Alternatives Considered

| Alternative | Pros | Cons | 判定 |
|-------------|------|------|------|
| 単一ローカルLLM | シンプル | 推論品質が低い | 却下 |
| 単一クラウドAPI | 高品質 | コスト大、Zero OpEx違反 | 却下 |
| Agent Framework (LangChain等) | 柔軟 | 抽象化過多、MCP非対応 | 却下 |

## References
- `docs/REQUIREMENTS.md` 1.2節（アーカイブ）
- MCP仕様: https://modelcontextprotocol.io
- ADR-0001: Local-First / Zero OpEx
