@book{bertrandmeyerObjectOrientedSoftwareConstruction1997,
  title = {Object-{{Oriented Software Construction}}},
  shorttitle = {Object-{{Oriented Software Construction}}},
  author = {Meyer, Bertrand},
  year = 1997,
  edition = {Second Edition},
  publisher = {Prentice Hall Professional Technical Reference},
  urldate = {2026-01-14},
  isbn = {978-0-13-629155-8},
  langid = {english}
}

@misc{LyraLocalFirstMCP,
  title = {Lyra: {{A Local-First MCP Server}} for {{AI-Collaborative Desktop Research}} with {{Evidence Graph Construction}}},
  doi = {10.5281/zenodo.18222598},
  urldate = {2026-01-14}
}

@online{nygardDocumentingArchitectureDecisions2011,
  title = {Documenting {{Architecture Decisions}}},
  author = {Nygard, Michael},
  date = {2011-11-15},
  url = {https://www.cognitect.com/blog/2011/11/15/documenting-architecture-decisions},
  urldate = {2026-01-14},
  langid = {american}
}

@misc{shibukiLyraLocalFirstMCP2026,
  title = {Lyra: {{A Local-First MCP Toolkit}} for {{AI-Collaborative Desktop Research}}},
  shorttitle = {Lyra},
  author = {Shibuki, Katsuya},
  year = 2026,
  month = jan,
  doi = {10.5281/zenodo.18218531},
  urldate = {2026-01-14},
  abstract = {Lyra is an open-source server implementing the Model Context Protocol (MCP) that enables AI assistants to conduct desktop research with structured provenance, providing accurate and auditable evidence. The software exposes research capabilities---web search, content extraction, natural language inference, and evidence graph construction---as structured tools that MCP-compatible AI clients can invoke directly. Every claim links to source fragments, which link to page URLs, creating an auditable chain from assertion to origin.},
  howpublished = {Zenodo},
  keywords = {academic research,evidence graph,local-first,MCP,Model Context Protocol,natural language inference,research automation}
}

@article{tyreeArchitectureDecisionsDemystifying2005,
  title = {Architecture Decisions: Demystifying Architecture},
  shorttitle = {Architecture Decisions},
  author = {Tyree, J. and Akerman, A.},
  year = 2005,
  month = mar,
  journal = {IEEE Software},
  volume = {22},
  number = {2},
  pages = {19--27},
  issn = {1937-4194},
  doi = {10.1109/MS.2005.27},
  urldate = {2026-01-14},
  abstract = {We believe that a key to demystifying architecture products lies in the architecture decisions concept. We can make the architecture more transparent and clarify its rationale for all stakeholders by explicitly documenting major architecture decisions.},
  keywords = {Art,Computer architecture,Concrete,design concepts,design methodologies,design notations and documentation,design representation,Documentation,Electric breakdown,Grounding,History,Software architecture,software architectures,Software design,software engineering design tools and techniques,System testing}
}

@inproceedings{vaithilingamExpectationVsExperience2022,
  title = {Expectation vs.~{{Experience}}: {{Evaluating}} the {{Usability}} of {{Code Generation Tools Powered}} by {{Large Language Models}}},
  shorttitle = {Expectation vs.~{{Experience}}},
  booktitle = {Extended {{Abstracts}} of the 2022 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L.},
  year = 2022,
  month = apr,
  series = {{{CHI EA}} '22},
  pages = {1--7},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3491101.3519665},
  urldate = {2026-01-14},
  abstract = {Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in general-purpose programming languages such as Python. However, there are few human studies on the usability of these tools and how they fit the programming workflow. In this work, we conducted a within-subjects user study with 24 participants to understand how programmers use and perceive Copilot, a LLM-based code generation tool. We found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online. However, participants did face difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for improving the design of Copilot based on our observations and participants' feedback.},
  isbn = {978-1-4503-9156-6}
}
