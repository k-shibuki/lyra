<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2026-01-04">

<title>Lyra: A Local-First MCP Server for AI-Collaborative Desktop Research with Evidence Graph Construction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="paper_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="paper_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap-63c9fca745fb4d1db5cea1b37fd4ab9a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lyra: A Local-First MCP Server for AI-Collaborative Desktop Research with Evidence Graph Construction</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Katsuya Shibuki <a href="https://orcid.org/0000-0003-3570-5038" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            1
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 4, 2026</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="summary" class="level1">
<h1>Summary</h1>
<p>Research demands auditable evidence chains—the ability to trace every claim back to its source. Lyra is an open-source server implementing the Model Context Protocol <span class="citation" data-cites="WhatModelContext">(MCP, <a href="#ref-WhatModelContext" role="doc-biblioref">Anthropic 2024</a>)</span>—a standard interface for connecting AI assistants to external tools—that enables AI assistants to conduct desktop research using structured provenance, providing accurate and auditable evidence. The software exposes research capabilities—web search, content extraction, natural language inference, and evidence graph construction—as structured tools that MCP-compatible AI clients can invoke directly.</p>
<p>I designed Lyra to separate strategic reasoning—performed by the AI assistant in the MCP client—from mechanical execution: evidence discovery, classification, and scoring (Figure 1).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/figure_1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>System architecture. The MCP server runs on the host; ML inference containers are network-isolated to prevent data exfiltration.</figcaption>
</figure>
</div>
<p>The AI assistant handles query design and synthesis, while Lyra executes search, extraction, and NLI-based stance detection. Lyra functions as a navigation tool: it discovers and organizes relevant sources, while detailed analysis of primary sources remains the researcher’s responsibility (Figure 2).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/figure_2.png" class="img-fluid figure-img" style="width:60.0%"></p>
<figcaption>Three-layer collaboration. Strategic reasoning resides in the MCP client; Lyra executes mechanical tasks. Primary source analysis remains the researcher’s responsibility.</figcaption>
</figure>
</div>
<p>The software incorporates three machine learning components for local GPU inference: a 3B-parameter language model <span class="citation" data-cites="qwenQwen25TechnicalReport2025">(Qwen2.5, <a href="#ref-qwenQwen25TechnicalReport2025" role="doc-biblioref">Qwen et al. 2025</a>)</span> for claim extraction, BGE-M3 embeddings <span class="citation" data-cites="chenM3EmbeddingMultiLingualityMultiFunctionality2024">(<a href="#ref-chenM3EmbeddingMultiLingualityMultiFunctionality2024" role="doc-biblioref">Chen et al. 2024</a>)</span> for semantic search, and a DeBERTa-based classifier <span class="citation" data-cites="heDeBERTaDecodingenhancedBERT2021">(<a href="#ref-heDeBERTaDecodingenhancedBERT2021" role="doc-biblioref">He et al. 2021</a>)</span> for stance detection. Lyra constructs an <strong>evidence graph</strong> linking extracted claims to source fragments with structured provenance metadata (Figure 3).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figures/figure_3.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption>Evidence graph structure. Fragments extracted from pages link to claims with NLI stance labels. Bayesian confidence aggregates weighted evidence.</figcaption>
</figure>
</div>
<p>Each claim accumulates a Bayesian confidence score calculated via Beta distribution updating <span class="citation" data-cites="gelmanBayesianDataAnalysis2013">(<a href="#ref-gelmanBayesianDataAnalysis2013" role="doc-biblioref">Gelman et al. 2013</a>)</span> over evidence edges weighted by Natural Language Inference <span class="citation" data-cites="bowmanLargeAnnotatedCorpus2015">(NLI, <a href="#ref-bowmanLargeAnnotatedCorpus2015" role="doc-biblioref">Bowman et al. 2015</a>)</span> judgments—automated classification of whether a text supports, refutes, or is neutral toward a claim—enabling transparent assessment of evidence quality.</p>
</section>
<section id="statement-of-need" class="level1">
<h1>Statement of Need</h1>
<p>Lyra targets academic researchers who require auditable evidence chains—the ability to trace claims to their sources—for verifying conclusions and enabling reproducibility. Large language models, however, are inherently probabilistic; verifying that AI-generated citations accurately reflect source materials demands substantial manual effort. Existing tools address different aspects of this challenge: cloud-based assistants <span class="citation" data-cites="Perplexity ElicitAIScientific">(<a href="#ref-Perplexity" role="doc-biblioref">Perplexity AI 2022</a>; <a href="#ref-ElicitAIScientific" role="doc-biblioref">Elicit 2021</a>)</span> provide rapid retrieval with citation links; browser automation <span class="citation" data-cites="SeleniumHQSelenium2013 MicrosoftPlaywright2019">(<a href="#ref-SeleniumHQSelenium2013" role="doc-biblioref">Selenium 2013</a>; <a href="#ref-MicrosoftPlaywright2019" role="doc-biblioref">Microsoft 2019</a>)</span> offers programmatic access; RAG frameworks <span class="citation" data-cites="chaseLangChain2022 liuLlamaIndex2022">(<a href="#ref-chaseLangChain2022" role="doc-biblioref">Chase 2022</a>; <a href="#ref-liuLlamaIndex2022" role="doc-biblioref">Liu 2022</a>)</span> specialize in document retrieval. Lyra takes a different approach, prioritizing structured provenance for auditable evidence chains.</p>
<p>From a context engineering perspective—designing systems that supply AI models with accurate, relevant information—Lyra constructs a transparent evidence graph that provides AI clients with traceable information. Every claim links to source fragments, which link to page URLs, creating an auditable chain from assertion to origin. The graph explicitly represents both supporting and refuting evidence, with Bayesian confidence scores quantifying the balance. Researchers can trace any claim back to its source text and evaluate the reasoning path themselves.</p>
<p>The software runs entirely on local hardware, eliminating dependence on external APIs and ensuring research data remains under researcher control. Multi-source search aggregates browser-based web search and academic APIs <span class="citation" data-cites="SemanticScholarAcademic priemOpenAlexFullyopenIndex2022">(<a href="#ref-SemanticScholarAcademic" role="doc-biblioref">Allen Institute for AI 2025</a>; <a href="#ref-priemOpenAlexFullyopenIndex2022" role="doc-biblioref">Priem, Piwowar, and Orr 2022</a>)</span> with Digital Object Identifier (DOI) based deduplication. A human-in-the-loop mechanism enables researchers to correct NLI judgments; these corrections are accumulated for planned domain adaptation via Low-Rank Adaptation <span class="citation" data-cites="huLoRALowRankAdaptation2021">(LoRA, <a href="#ref-huLoRALowRankAdaptation2021" role="doc-biblioref">Hu et al. 2021</a>)</span> fine-tuning.</p>
<p>The software comprises approximately 76,000 lines of Python source code and 95,000 lines of tests. I documented design rationale in 17 Architecture Decision Records covering local-first principles, evidence graph structure, and security models.</p>
</section>
<section id="acknowledgements" class="level1">
<h1>Acknowledgements</h1>
<p>Lyra builds upon several open-source projects: Ollama <span class="citation" data-cites="OllamaOllama2023">(<a href="#ref-OllamaOllama2023" role="doc-biblioref">Ollama 2023</a>)</span> for local language model runtime, Playwright <span class="citation" data-cites="MicrosoftPlaywright2019">(<a href="#ref-MicrosoftPlaywright2019" role="doc-biblioref">Microsoft 2019</a>)</span> for browser automation, Trafilatura <span class="citation" data-cites="barbaresiTrafilaturaWebScraping2021">(<a href="#ref-barbaresiTrafilaturaWebScraping2021" role="doc-biblioref">Barbaresi 2021</a>)</span> for web content extraction, and Hugging Face Transformers <span class="citation" data-cites="wolfTransformersStateoftheArtNatural2020">(<a href="#ref-wolfTransformersStateoftheArtNatural2020" role="doc-biblioref">Wolf et al. 2020</a>)</span> for NLI and embedding models. Academic metadata is provided by the Semantic Scholar <span class="citation" data-cites="SemanticScholarAcademic">(<a href="#ref-SemanticScholarAcademic" role="doc-biblioref">Allen Institute for AI 2025</a>)</span> and OpenAlex <span class="citation" data-cites="priemOpenAlexFullyopenIndex2022">(<a href="#ref-priemOpenAlexFullyopenIndex2022" role="doc-biblioref">Priem, Piwowar, and Orr 2022</a>)</span> APIs.</p>
</section>
<section id="references" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-SemanticScholarAcademic" class="csl-entry" role="listitem">
Allen Institute for AI. 2025. <span>“Semantic <span>Scholar Academic Graph API</span>.”</span> 2025. <a href="https://www.semanticscholar.org/product/api">https://www.semanticscholar.org/product/api</a>.
</div>
<div id="ref-WhatModelContext" class="csl-entry" role="listitem">
Anthropic. 2024. <span>“What Is the <span>Model Context Protocol</span> (<span>MCP</span>)?”</span> 2024. <a href="https://modelcontextprotocol.io/docs/getting-started/intro">https://modelcontextprotocol.io/docs/getting-started/intro</a>.
</div>
<div id="ref-barbaresiTrafilaturaWebScraping2021" class="csl-entry" role="listitem">
Barbaresi, Adrien. 2021. <span>“Trafilatura: <span>A Web Scraping Library</span> and <span>Command-Line Tool</span> for <span>Text Discovery</span> and <span>Extraction</span>.”</span> In <em>Proceedings of the 59th <span>Annual Meeting</span> of the <span>Association</span> for <span>Computational Linguistics</span> and the 11th <span>International Joint Conference</span> on <span>Natural Language Processing</span>: <span>System Demonstrations</span></em>, edited by Heng Ji, Jong C. Park, and Rui Xia, 122–31. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2021.acl-demo.15">https://doi.org/10.18653/v1/2021.acl-demo.15</a>.
</div>
<div id="ref-bowmanLargeAnnotatedCorpus2015" class="csl-entry" role="listitem">
Bowman, Samuel R., Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. <span>“A Large Annotated Corpus for Learning Natural Language Inference.”</span> August 21, 2015. <a href="https://doi.org/10.48550/arXiv.1508.05326">https://doi.org/10.48550/arXiv.1508.05326</a>.
</div>
<div id="ref-chaseLangChain2022" class="csl-entry" role="listitem">
Chase, Harrison. 2022. <span>“<span>LangChain</span>.”</span> <a href="https://github.com/langchain-ai/langchain">https://github.com/langchain-ai/langchain</a>.
</div>
<div id="ref-chenM3EmbeddingMultiLingualityMultiFunctionality2024" class="csl-entry" role="listitem">
Chen, Jianlv, Shitao Xiao, Peitian Zhang, Kun Luo, Defu Lian, and Zheng Liu. 2024. <span>“M3-<span>Embedding</span>: <span>Multi-Linguality</span>, <span>Multi-Functionality</span>, <span>Multi-Granularity Text Embeddings Through Self-Knowledge Distillation</span>.”</span> February 5, 2024. <a href="https://arxiv.org/abs/2402.03216v5">https://arxiv.org/abs/2402.03216v5</a>.
</div>
<div id="ref-ElicitAIScientific" class="csl-entry" role="listitem">
Elicit. 2021. <span>“Elicit: <span>AI</span> for Scientific Research.”</span> 2021. <a href="https://elicit.com/welcome">https://elicit.com/welcome</a>.
</div>
<div id="ref-gelmanBayesianDataAnalysis2013" class="csl-entry" role="listitem">
Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2013. <em>Bayesian <span>Data Analysis</span></em>. CRC Press. <a href="https://books.google.com?id=eSHSBQAAQBAJ">https://books.google.com?id=eSHSBQAAQBAJ</a>.
</div>
<div id="ref-heDeBERTaDecodingenhancedBERT2021" class="csl-entry" role="listitem">
He, Pengcheng, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2021. <span>“<span>DeBERTa</span>: <span class="nocase">Decoding-enhanced BERT</span> with <span>Disentangled Attention</span>.”</span> October 6, 2021. <a href="https://doi.org/10.48550/arXiv.2006.03654">https://doi.org/10.48550/arXiv.2006.03654</a>.
</div>
<div id="ref-huLoRALowRankAdaptation2021" class="csl-entry" role="listitem">
Hu, Edward J., Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. <span>“<span>LoRA</span>: <span>Low-Rank Adaptation</span> of <span>Large Language Models</span>.”</span> October 16, 2021. <a href="https://doi.org/10.48550/arXiv.2106.09685">https://doi.org/10.48550/arXiv.2106.09685</a>.
</div>
<div id="ref-liuLlamaIndex2022" class="csl-entry" role="listitem">
Liu, Jerry. 2022. <span>“<span>LlamaIndex</span>.”</span> <a href="https://doi.org/10.5281/zenodo.1234">https://doi.org/10.5281/zenodo.1234</a>.
</div>
<div id="ref-MicrosoftPlaywright2019" class="csl-entry" role="listitem">
Microsoft. 2019. <span>“Playwright.”</span> <a href="https://github.com/microsoft/playwright">https://github.com/microsoft/playwright</a>.
</div>
<div id="ref-OllamaOllama2023" class="csl-entry" role="listitem">
Ollama. 2023. <span>“Ollama.”</span> <a href="https://github.com/ollama/ollama">https://github.com/ollama/ollama</a>.
</div>
<div id="ref-Perplexity" class="csl-entry" role="listitem">
Perplexity AI. 2022. <span>“Perplexity.”</span> 2022. <a href="https://www.perplexity.ai/">https://www.perplexity.ai/</a>.
</div>
<div id="ref-priemOpenAlexFullyopenIndex2022" class="csl-entry" role="listitem">
Priem, Jason, Heather Piwowar, and Richard Orr. 2022. <span>“<span>OpenAlex</span>: <span>A</span> Fully-Open Index of Scholarly Works, Authors, Venues, Institutions, and Concepts.”</span> June 17, 2022. <a href="https://doi.org/10.48550/arXiv.2205.01833">https://doi.org/10.48550/arXiv.2205.01833</a>.
</div>
<div id="ref-qwenQwen25TechnicalReport2025" class="csl-entry" role="listitem">
Qwen, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, et al. 2025. <span>“Qwen2.5 <span>Technical Report</span>.”</span> January 3, 2025. <a href="https://doi.org/10.48550/arXiv.2412.15115">https://doi.org/10.48550/arXiv.2412.15115</a>.
</div>
<div id="ref-SeleniumHQSelenium2013" class="csl-entry" role="listitem">
Selenium. 2013. <span>“Selenium.”</span> <a href="https://github.com/SeleniumHQ/selenium">https://github.com/SeleniumHQ/selenium</a>.
</div>
<div id="ref-wolfTransformersStateoftheArtNatural2020" class="csl-entry" role="listitem">
Wolf, Thomas, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, et al. 2020. <span>“Transformers: <span class="nocase">State-of-the-Art Natural Language Processing</span>.”</span> In <em>Proceedings of the 2020 <span>Conference</span> on <span>Empirical Methods</span> in <span>Natural Language Processing</span>: <span>System Demonstrations</span></em>, edited by Qun Liu and David Schlangen, 38–45. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.emnlp-demos.6">https://doi.org/10.18653/v1/2020.emnlp-demos.6</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>