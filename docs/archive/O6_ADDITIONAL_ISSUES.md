# O.6 è¿½åŠ ä»•æ§˜é•åèª¿æŸ»çµæœ

## èª¿æŸ»æ—¥: 2025-12-11

O.6ã®å®Ÿè£…å®Œäº†å¾Œã€åŒæ§˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ä»–ã®ä»•æ§˜é•åãŒãªã„ã‹èª¿æŸ»ã—ãŸçµæœã€‚

---

## å•é¡Œ3: èªè¨¼å¾…ã¡ã‚­ãƒ¥ãƒ¼ã§ä¿å­˜ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå¾Œç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆã§å†åˆ©ç”¨ã•ã‚Œã¦ã„ãªã„ âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-11  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `src/crawler/fetcher.py:1086-1137`  
**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_auth_session_reuse_flow.py`

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/crawler/fetcher.py:933` - `BrowserFetcher.fetch()`
- `src/search/browser_search_provider.py` - `BrowserSearchProvider.search()`ï¼ˆè¦ç¢ºèªï¼‰

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/crawler/fetcher.py:933-970
async def fetch(self, url: str, ...):
    domain = urlparse(url).netloc.lower()
    
    # æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯ãªã—
    browser, context = await self._ensure_browser(headful=headful, task_id=task_id)
    
    page = await context.new_page()
    # Cookieè¨­å®šãªã—ã§ç›´æ¥ãƒŠãƒ“ã‚²ãƒ¼ãƒˆ
    response = await page.goto(url, ...)
    
    # èªè¨¼å¾…ã¡ãŒç™ºç”Ÿã—ãŸã‚‰ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€ã ã‘
    if _is_challenge_page(content, {}):
        if allow_intervention and queue_auth and task_id:
            queue = get_intervention_queue()
            queue_id = await queue.enqueue(...)  # ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€ã ã‘
            return FetchResult(ok=False, reason="auth_required", ...)
```

### å•é¡Œç‚¹

1. **æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯ãªã—**: `fetch()`ã®é–‹å§‹æ™‚ã«ã€`InterventionQueue.get_session_for_domain()`ã§æ—¢å­˜ã®èªè¨¼æ¸ˆã¿ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ãªã„
2. **Cookieè¨­å®šãªã—**: èªè¨¼å¾…ã¡ã‚­ãƒ¥ãƒ¼ã§ä¿å­˜ã•ã‚ŒãŸCookieã‚’ã€ãƒ–ãƒ©ã‚¦ã‚¶ã®contextã«è¨­å®šã™ã‚‹å‡¦ç†ãŒãªã„
3. **å†èªè¨¼ã®ç™ºç”Ÿ**: èªè¨¼æ¸ˆã¿ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚‚ã€æ¯å›èªè¨¼å¾…ã¡ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§3.6.1: "ã‚»ãƒƒã‚·ãƒ§ãƒ³å…±æœ‰: èªè¨¼æ¸ˆã¿Cookie/ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯åŒä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å¾Œç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆã§è‡ªå‹•å†åˆ©ç”¨"
- Â§3.6.1: "ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ™ãƒ¼ã‚¹èªè¨¼ç®¡ç†: åŒä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã®èªè¨¼ã¯1å›ã®çªç ´ã§è¤‡æ•°ã‚¿ã‚¹ã‚¯/URLã«é©ç”¨ã•ã‚Œã‚‹"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: `fetch()`ã®é–‹å§‹æ™‚ã«ã€èªè¨¼å¾…ã¡ã‚­ãƒ¥ãƒ¼ã‹ã‚‰æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—ã—ã€Cookieã‚’ãƒ–ãƒ©ã‚¦ã‚¶contextã«è¨­å®šã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- `src/crawler/fetcher.py:933` - `BrowserFetcher.fetch()`

**ä¿®æ­£æ¡ˆ**:
```python
async def fetch(self, url: str, ...):
    domain = urlparse(url).netloc.lower()
    
    # èªè¨¼å¾…ã¡ã‚­ãƒ¥ãƒ¼ã‹ã‚‰æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
    from src.utils.notification import get_intervention_queue
    queue = get_intervention_queue()
    existing_session = await queue.get_session_for_domain(domain, task_id=task_id)
    
    browser, context = await self._ensure_browser(headful=headful, task_id=task_id)
    
    # æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒã‚ã‚Œã°Cookieã‚’è¨­å®š
    if existing_session and existing_session.get("cookies"):
        cookies = existing_session["cookies"]
        # Playwrightã®Cookieå½¢å¼ã«å¤‰æ›
        playwright_cookies = [
            {
                "name": c.get("name"),
                "value": c.get("value"),
                "domain": c.get("domain", domain),
                "path": c.get("path", "/"),
                "expires": c.get("expires"),
                "httpOnly": c.get("httpOnly", False),
                "secure": c.get("secure", True),
                "sameSite": c.get("sameSite", "Lax"),
            }
            for c in cookies
        ]
        await context.add_cookies(playwright_cookies)
        logger.info(
            "Applied stored authentication cookies",
            domain=domain,
            cookie_count=len(playwright_cookies),
        )
    
    page = await context.new_page()
    # ... ä»¥ä¸‹æ—¢å­˜ã®å‡¦ç†
```

**æ³¨æ„ç‚¹**:
- Cookieã®æœ‰åŠ¹æœŸé™ãƒã‚§ãƒƒã‚¯ãŒå¿…è¦
- ã‚µãƒ–ãƒ‰ãƒ¡ã‚¤ãƒ³å¯¾å¿œï¼ˆ`.example.com`ã¨`www.example.com`ï¼‰
- `browser_search_provider.py`ã§ã‚‚åŒæ§˜ã®å‡¦ç†ãŒå¿…è¦ã‹ç¢ºèª

---

## å•é¡Œ4: BrowserSearchProviderã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨æœªå®Ÿè£…ï¼ˆè¦ç¢ºèªï¼‰âœ… ç¢ºèªå®Œäº†

**ç¢ºèªå®Œäº†æ—¥**: 2025-12-15

### ç¢ºèªçµæœ

**ç¾çŠ¶ã®å®Ÿè£…**:
- `BrowserSearchProvider._ensure_browser()`ã§æ—¢å­˜ã®browser contextã‚’å†åˆ©ç”¨ã—Cookieã‚’ä¿æŒ
- `_sessions`è¾æ›¸ã§ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç®¡ç†
- èªè¨¼å¾…ã¡ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã®ç›´æ¥å–å¾—ã¯æœªå®Ÿè£…

**çµè«–**: 
- æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã¯é€šå¸¸èªè¨¼ä¸è¦ã®ãŸã‚ã€ç¾çŠ¶ã®å®Ÿè£…ã§ä»•æ§˜è¦ä»¶ã‚’æº€ãŸã—ã¦ã„ã‚‹
- æ—¢å­˜contextå†åˆ©ç”¨ã«ã‚ˆã‚ŠCookie/ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ä¿æŒã•ã‚Œã‚‹ï¼ˆÂ§3.6.1æº–æ‹ ï¼‰
- èªè¨¼ãŒå¿…è¦ãªç‰¹æ®Šã‚±ãƒ¼ã‚¹ï¼ˆGoogleãƒ­ã‚°ã‚¤ãƒ³å¿…é ˆæ¤œç´¢ç­‰ï¼‰ã¯ã€BrowserFetcherã®èªè¨¼å¾…ã¡ã‚­ãƒ¥ãƒ¼æ©Ÿèƒ½ã§å¯¾å¿œå¯èƒ½

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/search/browser_search_provider.py` - `BrowserSearchProvider.search()`

---

## å•é¡Œ5: start_session()ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ãå‡¦ç†ãŒæœªå®Ÿè£… âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-11  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `src/utils/notification.py:1165-1200`, `src/crawler/fetcher.py:738-960` (Chromeè‡ªå‹•èµ·å‹•)  
**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_start_session_browser_flow.py`, `tests/scripts/debug_chrome_auto_start.py`

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/utils/notification.py:1077` - `InterventionQueue.start_session()`

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/utils/notification.py:1077
async def start_session(self, task_id: str, ...):
    # URLã‚’è¿”ã™ã ã‘ã§ã€ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ãå‡¦ç†ãŒãªã„
    return {
        "ok": True,
        "session_started": True,
        "count": len(items),
        "items": items,  # URLã®ãƒªã‚¹ãƒˆã®ã¿
    }
```

### å•é¡Œç‚¹

1. **ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ãå‡¦ç†ãŒãªã„**: `start_session()`ã¯URLã‚’è¿”ã™ã ã‘ã§ã€å®Ÿéš›ã«ãƒ–ãƒ©ã‚¦ã‚¶ã§URLã‚’é–‹ãå‡¦ç†ãŒãªã„
2. **ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å‰é¢åŒ–ãŒãªã„**: ä»•æ§˜æ›¸ã§ã¯ã€Œèªè¨¼å¾…ã¡URLã‚’é–‹ã„ã¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å‰é¢åŒ–ã™ã‚‹ã®ã¿ã€ã¨ã‚ã‚‹ãŒã€å®Ÿè£…ã•ã‚Œã¦ã„ãªã„
3. **ãƒ¦ãƒ¼ã‚¶ãƒ¼æ‰‹å‹•æ“ä½œãŒå¿…è¦**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ãå¿…è¦ãŒã‚ã‚‹

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§3.6.1: "æœ€å°ä»‹å…¥åŸå‰‡: èªè¨¼å¾…ã¡URLã‚’é–‹ã„ã¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å‰é¢åŒ–ã™ã‚‹ã®ã¿"
- Â§3.6.1: "CDPã®å®‰å…¨é‹ç”¨: è¨±å¯: `Page.navigate`ï¼ˆURLã‚’é–‹ãï¼‰ã€`Page.bringToFront`ï¼ˆå‰é¢åŒ–ã€OS APIä½µç”¨æ¨å¥¨ï¼‰"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: `start_session()`ã§ã€è¿”ã•ã‚ŒãŸURLã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãã€ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å‰é¢åŒ–ã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- `src/utils/notification.py:1077` - `InterventionQueue.start_session()`

**ä¿®æ­£æ¡ˆ**:
```python
async def start_session(self, task_id: str, ...):
    # ... æ—¢å­˜ã®å‡¦ç†ï¼ˆURLå–å¾—ãƒ»in_progressãƒãƒ¼ã‚¯ï¼‰ ...
    
    # ãƒ–ãƒ©ã‚¦ã‚¶ã§URLã‚’é–‹ãï¼ˆå®‰å…¨ãªæ–¹æ³•ã§ï¼‰
    if items:
        from src.search.browser_search_provider import BrowserSearchProvider
        provider = BrowserSearchProvider()
        await provider._ensure_browser()
        
        if provider._context:
            # æœ€åˆã®URLã‚’é–‹ã
            page = await provider._context.new_page()
            await page.goto(items[0]["url"], wait_until="domcontentloaded")
            
            # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å‰é¢åŒ–ï¼ˆå®‰å…¨ãªæ–¹æ³•ã§ï¼‰
            from src.utils.notification import get_intervention_manager
            manager = get_intervention_manager()
            await manager._bring_tab_to_front(page)
            
            logger.info(
                "Opened authentication URL in browser",
                url=items[0]["url"],
                total_count=len(items),
            )
    
    return {
        "ok": True,
        "session_started": True,
        "count": len(items),
        "items": items,
    }
```

**æ³¨æ„ç‚¹**:
- è¤‡æ•°ã®URLãŒã‚ã‚‹å ´åˆã€æœ€åˆã®URLã®ã¿é–‹ãï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§ä»–ã®URLã‚’é–‹ãæƒ³å®šï¼‰
- `Page.navigate`ã¨`Page.bringToFront`ã®ã¿ä½¿ç”¨ï¼ˆDOMæ“ä½œã¯ç¦æ­¢ï¼‰
- OS APIã§ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å‰é¢åŒ–ã‚‚ä½µç”¨

---

## å•é¡Œ6: Chromeãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åãŒä»•æ§˜ã¨ä¸ä¸€è‡´ï¼ˆè¦ç¢ºèªï¼‰âœ… ç¢ºèªå®Œäº†

**ç¢ºèªå®Œäº†æ—¥**: 2025-12-15

### ç¢ºèªçµæœ

**ç¾çŠ¶ã®å®Ÿè£…**:
- WSL: `$env:LocalApplicationData\LyraChrome`
- Linux: `$HOME/.local/share/lyra-chrome`
- å°‚ç”¨ã®`--user-data-dir`ã‚’ä½¿ç”¨ã—ã€æ—¥å¸¸ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Œå…¨ã«åˆ†é›¢

**çµè«–**:
- å°‚ç”¨ã®`user-data-dir`ï¼ˆ`LyraChrome`ï¼‰ã«ã‚ˆã‚Šã€æ—¥å¸¸ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å½±éŸ¿ã¯é®æ–­ã•ã‚Œã¦ã„ã‚‹
- `--profile-directory`ã¯æœªæŒ‡å®šã ãŒã€å°‚ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚æ©Ÿèƒ½çš„ã«ã¯å•é¡Œãªã—
- ä»•æ§˜æ›¸ã®`Profile-Research`ã¯å‚è€ƒä¾‹ã§ã‚ã‚Šã€ç¾åœ¨ã®å®Ÿè£…ã§ä»•æ§˜ã®æ„å›³ï¼ˆç ”ç©¶ç”¨éš”é›¢ï¼‰ã¯é”æˆã•ã‚Œã¦ã„ã‚‹

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `scripts/chrome.sh:284` - Chromeèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§3.2: "èª¿æŸ»å°‚ç”¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«é‹ç”¨: ç ”ç©¶å°‚ç”¨ã®Chromeãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’`--user-data-dir`/`--profile-directory`ã§å›ºå®šåŒ–ï¼ˆä¾‹: `--profile-directory="Profile-Research"`ï¼‰"
- Â§4.3.1: "å®‰å…¨ç­–: `Profile-Research`ã®ã¿ã‚’å¯¾è±¡ã€æ—¥å¸¸ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å½±éŸ¿ã‚’é®æ–­"

---

## å•é¡Œ7: LocalStorageã®ç ”ç©¶ç”¨éš”é›¢ã®ç¢ºèªï¼ˆè¦ç¢ºèªï¼‰âœ… ç¢ºèªå®Œäº†

**ç¢ºèªå®Œäº†æ—¥**: 2025-12-15

### ç¢ºèªçµæœ

**ç¾çŠ¶ã®å®Ÿè£…**:
- å°‚ç”¨ã®`user-data-dir`ï¼ˆ`LyraChrome` / `lyra-chrome`ï¼‰ã‚’ä½¿ç”¨
- Chromeã¯`user-data-dir`ã”ã¨ã«ç‹¬ç«‹ã—ãŸCookie/LocalStorage/IndexedDBã‚’ä¿æŒ

**çµè«–**:
- å°‚ç”¨`user-data-dir`ã«ã‚ˆã‚Šã€Cookie/LocalStorageã¯è‡ªå‹•çš„ã«ç ”ç©¶ç”¨ã¨ã—ã¦éš”é›¢ã•ã‚Œã¦ã„ã‚‹
- æ—¥å¸¸ã®ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ã¯å®Œå…¨ã«åˆ†é›¢ã•ã‚Œã¦ã„ã‚‹
- **å•é¡Œãªã—**

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- Chromeãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šå…¨èˆ¬

---

## å„ªå…ˆåº¦

**å•é¡Œ3**: ğŸ”´ é«˜ï¼ˆä»•æ§˜é•åï¼‰
- Â§3.6.1ã®æ ¸å¿ƒæ©Ÿèƒ½ã€Œã‚»ãƒƒã‚·ãƒ§ãƒ³å…±æœ‰ã€ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„
- èªè¨¼å®Œäº†å¾Œã‚‚å†èªè¨¼ãŒå¿…è¦ã«ãªã‚Šã€é‹ç”¨åŠ¹ç‡ãŒä½ä¸‹

**å•é¡Œ5**: ğŸ”´ é«˜ï¼ˆä»•æ§˜é•åï¼‰
- Â§3.6.1ã®ã€Œæœ€å°ä»‹å…¥åŸå‰‡ã€ã«é•å
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ãå¿…è¦ãŒã‚ã‚Šã€UXãŒæ‚ªã„

**å•é¡Œ4**: âœ… ç¢ºèªå®Œäº†
- æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã¯èªè¨¼ä¸è¦ã®ãŸã‚ç¾çŠ¶ã§å•é¡Œãªã—
- æ—¢å­˜contextå†åˆ©ç”¨ã«ã‚ˆã‚ŠCookie/ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿æŒæ¸ˆã¿

**å•é¡Œ6**: âœ… ç¢ºèªå®Œäº†
- å°‚ç”¨`user-data-dir`ã§æ—¥å¸¸ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åˆ†é›¢æ¸ˆã¿
- æ©Ÿèƒ½çš„ã«ã¯å•é¡Œãªã—

**å•é¡Œ7**: âœ… ç¢ºèªå®Œäº†
- å°‚ç”¨`user-data-dir`ã«ã‚ˆã‚ŠCookie/LocalStorageã¯è‡ªå‹•éš”é›¢
- å•é¡Œãªã—

---

## é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | å½¹å‰² | ä¿®æ­£å†…å®¹ |
|---------|------|---------|
| `src/crawler/fetcher.py` | ãƒ–ãƒ©ã‚¦ã‚¶ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼ | æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—ãƒ»Cookieè¨­å®š |
| `src/utils/notification.py` | èªè¨¼å¾…ã¡ã‚­ãƒ¥ãƒ¼ | start_session()ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ãå‡¦ç†è¿½åŠ  |
| `src/search/browser_search_provider.py` | ãƒ–ãƒ©ã‚¦ã‚¶æ¤œç´¢ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ | æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—ãƒ»Cookieè¨­å®šï¼ˆè¦ç¢ºèªï¼‰ |
| `scripts/chrome.sh` | Chromeèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ | ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åæŒ‡å®šï¼ˆè¦ç¢ºèªï¼‰ |

---

## å•é¡Œ8: BrowserSearchProviderã§ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠãƒ­ã‚¸ãƒƒã‚¯ãŒæœªå®Ÿè£…

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/search/browser_search_provider.py:280` - `BrowserSearchProvider.search()`

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/search/browser_search_provider.py:280-283
# Determine engine to use
engine = self._default_engine
if options.engines:
    engine = options.engines[0]  # å˜ç´”ã«æœ€åˆã®ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨
```

### å•é¡Œç‚¹

1. **é‡ã¿ä»˜ã‘é¸æŠãŒãªã„**: ä»•æ§˜ã§ã¯ã€Œã‚«ãƒ†ã‚´ãƒªï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹/å­¦è¡“/æ”¿åºœ/æŠ€è¡“ï¼‰ã§å±¤åˆ¥åŒ–ã—ã€éå»ã®ç²¾åº¦/å¤±æ•—ç‡/ãƒ–ãƒ­ãƒƒã‚¯ç‡ã§é‡ã¿ã‚’å­¦ç¿’ã€ã¨ã‚ã‚‹ãŒã€å®Ÿè£…ã•ã‚Œã¦ã„ãªã„
2. **ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ã®ãƒã‚§ãƒƒã‚¯ãŒãªã„**: ã‚¨ãƒ³ã‚¸ãƒ³ãŒ`open`çŠ¶æ…‹ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ä¸­ï¼‰ã§ã‚‚ä½¿ç”¨ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
3. **ã‚¨ãƒ³ã‚¸ãƒ³ãƒ˜ãƒ«ã‚¹ã®è¨˜éŒ²ãŒãªã„**: æ¤œç´¢æˆåŠŸ/å¤±æ•—ãŒ`engine_health`ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¨˜éŒ²ã•ã‚Œã¦ã„ãªã„
4. **ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠãŒãªã„**: ã‚¯ã‚¨ãƒªã®ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸã‚¨ãƒ³ã‚¸ãƒ³é¸æŠãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„
5. **ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ãƒ»ã‚¹ãƒ­ãƒƒãƒˆã®å®Ÿè£…ãŒãªã„**: ã€Œå›åç‡ã®æœ€å¾Œã®10%ã‚’ç‹™ã†é™å®šæ ã¨ã—ã¦Google/Braveã‚’æœ€å°é™é–‹æ”¾ã€ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§3.1: "ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠã¨é‡ã¿ä»˜ã‘: ã‚«ãƒ†ã‚´ãƒªï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹/å­¦è¡“/æ”¿åºœ/æŠ€è¡“ï¼‰ã§å±¤åˆ¥åŒ–ã—ã€éå»ã®ç²¾åº¦/å¤±æ•—ç‡/ãƒ–ãƒ­ãƒƒã‚¯ç‡ã§é‡ã¿ã‚’å­¦ç¿’"
- Â§3.1.4: "ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯/ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«: é€£ç¶šå¤±æ•—â‰¥2ã§`open`ã€æˆåŠŸ1å›ã§`half-open`â†’å®‰å®šã§`closed`"
- Â§3.1.4: "ãƒ˜ãƒ«ã‚¹ã®æ°¸ç¶šåŒ–: SQLiteã®`engine_health`ãƒ†ãƒ¼ãƒ–ãƒ«ã«EMAï¼ˆ1h/24hï¼‰ã‚’ä¿æŒã—ã€é‡ã¿ãƒ»QPSãƒ»æ¢ç´¢æ ã‚’è‡ªå‹•èª¿æ•´"
- Â§3.1: "ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ãƒ»ã‚¹ãƒ­ãƒƒãƒˆ: å›åç‡ã®æœ€å¾Œã®10%ã‚’ç‹™ã†é™å®šæ ã¨ã—ã¦Google/Braveã‚’æœ€å°é™é–‹æ”¾ï¼ˆå³æ ¼ãªQPSãƒ»å›æ•°ãƒ»æ™‚é–“å¸¯åˆ¶å¾¡ï¼‰"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: `BrowserSearchProvider.search()`ã§ã€é‡ã¿ä»˜ã‘ãƒ»ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ»ã‚«ãƒ†ã‚´ãƒªåˆ¥é¸æŠã‚’å®Ÿè£…ã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- `src/search/browser_search_provider.py:260` - `BrowserSearchProvider.search()`

**ä¿®æ­£æ¡ˆ**:
```python
async def search(self, query: str, options: SearchOptions | None = None) -> SearchResponse:
    # ... æ—¢å­˜ã®å‡¦ç† ...
    
    # ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠãƒ­ã‚¸ãƒƒã‚¯ï¼ˆé‡ã¿ä»˜ã‘ãƒ»ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«è€ƒæ…®ï¼‰
    from src.search.circuit_breaker import check_engine_available, record_engine_result
    from src.search.engine_config import get_engine_config_manager
    
    config_manager = get_engine_config_manager()
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
    category = self._detect_category(query)
    
    # åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ã‚¸ãƒ³ã‚’å–å¾—ï¼ˆã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«è€ƒæ…®ï¼‰
    if options.engines:
        candidate_engines = options.engines
    else:
        # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸã‚¨ãƒ³ã‚¸ãƒ³é¸æŠ
        candidate_engines = config_manager.get_engines_for_category(category)
        if not candidate_engines:
            candidate_engines = config_manager.get_default_engines()
    
    # é‡ã¿ä»˜ã‘ãƒ»ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    available_engines = []
    for engine_name in candidate_engines:
        if await check_engine_available(engine_name):
            engine_config = config_manager.get_engine(engine_name)
            if engine_config and engine_config.is_available:
                available_engines.append((engine_name, engine_config.weight))
    
    if not available_engines:
        # ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ãƒ»ã‚¹ãƒ­ãƒƒãƒˆã‚’è©¦è¡Œ
        lastmile_engines = config_manager.get_lastmile_engines()
        for engine_name in lastmile_engines:
            if await check_engine_available(engine_name):
                engine_config = config_manager.get_engine(engine_name)
                if engine_config and engine_config.is_available:
                    available_engines.append((engine_name, engine_config.weight))
                    break  # ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ã¯1ã¤ã ã‘
    
    if not available_engines:
        return SearchResponse(
            results=[],
            query=query,
            provider=self.name,
            error="No available engines",
            elapsed_ms=0,
        )
    
    # é‡ã¿ä»˜ã‘ã§é¸æŠï¼ˆç°¡æ˜“ç‰ˆ: é‡ã¿ã®é«˜ã„é †ï¼‰
    available_engines.sort(key=lambda x: x[1], reverse=True)
    engine = available_engines[0][0]
    
    # ... æ¤œç´¢å®Ÿè¡Œ ...
    
    # ã‚¨ãƒ³ã‚¸ãƒ³ãƒ˜ãƒ«ã‚¹ã®è¨˜éŒ²
    try:
        if response.ok:
            await record_engine_result(engine, success=True, latency_ms=elapsed_ms)
        else:
            is_captcha = parse_result.is_captcha if 'parse_result' in locals() else False
            await record_engine_result(engine, success=False, latency_ms=elapsed_ms, is_captcha=is_captcha)
    except Exception as e:
        logger.warning("Failed to record engine result", engine=engine, error=str(e))
    
    return response
```

**æ³¨æ„ç‚¹**:
- ã‚«ãƒ†ã‚´ãƒªåˆ¤å®šã¯ç°¡æ˜“ç‰ˆã§å®Ÿè£…ï¼ˆã‚¯ã‚¨ãƒªå†…å®¹ã‹ã‚‰æ¨å®šï¼‰
- é‡ã¿ä»˜ã‘é¸æŠã¯ç°¡æ˜“ç‰ˆï¼ˆé‡ã¿ã®é«˜ã„é †ï¼‰ã§å®Ÿè£…ã—ã€å¾Œã§å­¦ç¿’æ©Ÿèƒ½ã‚’è¿½åŠ 
- ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ãƒ»ã‚¹ãƒ­ãƒƒãƒˆã¯å›åç‡ã®åˆ¤å®šãŒå¿…è¦ï¼ˆåˆ¥é€”å®Ÿè£…ï¼‰

**å®Ÿè£…çŠ¶æ³ï¼ˆ2025-12-15ï¼‰**:
- âœ… ã‚«ãƒ†ã‚´ãƒªåˆ¤å®šï¼ˆ`_detect_category()`ï¼‰: å®Ÿè£…å®Œäº†
- âœ… ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠï¼ˆ`get_engines_for_category()`ï¼‰: å®Ÿè£…å®Œäº†
- âœ… ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ`check_engine_available()`ï¼‰: å®Ÿè£…å®Œäº†
- âœ… é‡ã¿ä»˜ã‘é¸æŠï¼ˆé™çš„è¨­å®šï¼‰: å®Ÿè£…å®Œäº†
- âœ… ã‚¨ãƒ³ã‚¸ãƒ³ãƒ˜ãƒ«ã‚¹è¨˜éŒ²ï¼ˆ`record_engine_result()`ï¼‰: å®Ÿè£…å®Œäº†
- âœ… å‹•çš„é‡ã¿å­¦ç¿’ï¼ˆéå»ã®ç²¾åº¦/å¤±æ•—ç‡/ãƒ–ãƒ­ãƒƒã‚¯ç‡ã«ã‚ˆã‚‹é‡ã¿èª¿æ•´ï¼‰: **å®Ÿè£…å®Œäº†**
- âŒ ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ãƒ»ã‚¹ãƒ­ãƒƒãƒˆ: æœªå®Ÿè£…ï¼ˆå•é¡Œ13ã§å®Ÿè£…äºˆå®šï¼‰

### å‹•çš„é‡ã¿å­¦ç¿’ã®å®Ÿè£…ï¼ˆå®Œäº†ï¼‰

**ç›®çš„**: éå»ã®ç²¾åº¦/å¤±æ•—ç‡/ãƒ–ãƒ­ãƒƒã‚¯ç‡ã‚’åŸºã«ã‚¨ãƒ³ã‚¸ãƒ³ã®é‡ã¿ã‚’å‹•çš„ã«èª¿æ•´ã™ã‚‹

**ä»•æ§˜æ›¸ã®è¦ä»¶**:
- Â§3.1.1: "ã‚«ãƒ†ã‚´ãƒªï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹/å­¦è¡“/æ”¿åºœ/æŠ€è¡“ï¼‰ã§å±¤åˆ¥åŒ–ã—ã€éå»ã®ç²¾åº¦/å¤±æ•—ç‡/ãƒ–ãƒ­ãƒƒã‚¯ç‡ã§é‡ã¿ã‚’å­¦ç¿’"
- Â§3.1.4: "ãƒ˜ãƒ«ã‚¹ã®æ°¸ç¶šåŒ–: SQLiteã®`engine_health`ãƒ†ãƒ¼ãƒ–ãƒ«ã«EMAï¼ˆ1h/24hï¼‰ã‚’ä¿æŒã—ã€é‡ã¿ãƒ»QPSãƒ»æ¢ç´¢æ ã‚’è‡ªå‹•èª¿æ•´"
- Â§4.6: "ãƒãƒªã‚·ãƒ¼è‡ªå‹•æ›´æ–°ï¼ˆé«˜é »åº¦ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ«ãƒ¼ãƒ—åˆ¶å¾¡ï¼‰: ã‚¤ãƒ™ãƒ³ãƒˆé§†å‹•: å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ã‚¯ã‚¨ãƒªå®Œäº†æ™‚ã«å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆæˆåŠŸ/å¤±æ•—/ãƒ–ãƒ­ãƒƒã‚¯ç¨®åˆ¥/ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’EMAã«åæ˜ ï¼‰"

**å®Ÿè£…å®Œäº†ï¼ˆ2025-12-15ï¼‰**:

| ãƒ•ã‚¡ã‚¤ãƒ« | å¤‰æ›´å†…å®¹ |
|---------|----------|
| `src/utils/schemas.py` | `EngineHealthMetrics`, `DynamicWeightResult` Pydanticãƒ¢ãƒ‡ãƒ«è¿½åŠ  |
| `src/storage/database.py` | `get_engine_health_metrics()` ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ  |
| `src/utils/policy_engine.py` | `calculate_dynamic_weight()`, `get_dynamic_engine_weight()` ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ  |
| `src/search/browser_search_provider.py` | `search()`ã§å‹•çš„é‡ã¿ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ä¿®æ­£ |
| `docs/sequences/dynamic_weight_flow.md` | ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ä½œæˆ |
| `tests/test_policy_engine.py` | `TestDynamicWeightCalculation` ã‚¯ãƒ©ã‚¹è¿½åŠ ï¼ˆ11ãƒ†ã‚¹ãƒˆï¼‰ |
| `tests/test_browser_search_provider.py` | `TestDynamicWeightUsage` ã‚¯ãƒ©ã‚¹è¿½åŠ ï¼ˆ3ãƒ†ã‚¹ãƒˆï¼‰ |
| `tests/scripts/debug_dynamic_weight_flow.py` | ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ |

**é‡ã¿è¨ˆç®—å¼**:
```
success_factor = 0.6 * success_rate_1h + 0.4 * success_rate_24h
captcha_penalty = 1.0 - (captcha_rate * 0.5)
latency_factor = 1.0 / (1.0 + median_latency_ms / 1000.0)
raw_weight = base_weight * success_factor * captcha_penalty * latency_factor
```

**æ™‚é–“æ¸›è¡°ï¼ˆ48æ™‚é–“ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå›å¸°ï¼‰**:
```
confidence = max(0.1, 1.0 - (hours_since_use / 48))
final_weight = confidence * raw_weight + (1 - confidence) * base_weight
```

| çµŒéæ™‚é–“ | ãƒ¡ãƒˆãƒªã‚¯ã‚¹åæ˜  | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåæ˜  |
|----------|---------------|---------------|
| 0-6æ™‚é–“ | 87-100% | 0-13% |
| 12æ™‚é–“ | 75% | 25% |
| 24æ™‚é–“ | 50% | 50% |
| 48æ™‚é–“ä»¥ä¸Š | 10% | 90% |

**ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ**:
```bash
# ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
pytest tests/test_policy_engine.py::TestDynamicWeightCalculation -v

# çµ±åˆãƒ†ã‚¹ãƒˆ
pytest tests/test_browser_search_provider.py::TestDynamicWeightUsage -v

# ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python tests/scripts/debug_dynamic_weight_flow.py
```

è©³ç´°ãªå®Ÿè£…ã«ã¤ã„ã¦ã¯ `docs/sequences/dynamic_weight_flow.md` ã‚’å‚ç…§ã€‚

---

## å•é¡Œ9: BrowserSearchProviderã§ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥QPSåˆ¶é™ãŒæœªå®Ÿè£… âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-15  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `src/search/browser_search_provider.py:155-158` (_last_search_timesè¿½åŠ ), `src/search/browser_search_provider.py:311-339` (_rate_limitæ‹¡å¼µ), `src/search/browser_search_provider.py:484` (searchå‘¼ã³å‡ºã—ä¿®æ­£)  
**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_engine_qps_flow.py`  
**ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³**: `docs/sequences/engine_qps_flow.md`

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/search/browser_search_provider.py:252` - `BrowserSearchProvider._rate_limit()`

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/search/browser_search_provider.py:252-258
async def _rate_limit(self) -> None:
    """Apply rate limiting between searches."""
    async with self._rate_limiter:
        elapsed = time.time() - self._last_search_time
        if elapsed < self._min_interval:
            await asyncio.sleep(self._min_interval - elapsed)
        self._last_search_time = time.time()
```

### å•é¡Œç‚¹

1. **ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥QPSåˆ¶é™ãŒãªã„**: ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚¸ãƒ³ã§åŒã˜`_min_interval`ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹
2. **ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®šã®QPSãŒåæ˜ ã•ã‚Œã¦ã„ãªã„**: `config/engines.yaml`ã§å®šç¾©ã•ã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ³åˆ¥QPSï¼ˆä¾‹: DuckDuckGo=0.2, Google=0.05ï¼‰ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§3.1: "ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡ï¼ˆä¸¦åˆ—åº¦=1ã€å³æ ¼QPSï¼‰ã¨ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ï¼ˆæ•…éšœåˆ‡æ›¿ãƒ»å†·å´ï¼‰ã‚’å®Ÿè£…"
- Â§4.3: "ã‚¨ãƒ³ã‚¸ãƒ³/ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡ã®æ˜ç¢ºåŒ–: ã‚¨ãƒ³ã‚¸ãƒ³QPSâ‰¤0.25ï¼ˆ1ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/4sï¼‰ã€ãƒ‰ãƒ¡ã‚¤ãƒ³QPSâ‰¤0.2ã€ä¸¦åˆ—åº¦=1ã‚’åŸå‰‡"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: `_rate_limit()`ã§ã€ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã®QPSåˆ¶é™ã‚’é©ç”¨ã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- `src/search/browser_search_provider.py:252` - `BrowserSearchProvider._rate_limit()`

**ä¿®æ­£æ¡ˆ**:
```python
async def _rate_limit(self, engine: str | None = None) -> None:
    """Apply rate limiting between searches (per-engine QPS)."""
    from src.search.engine_config import get_engine_config_manager
    
    config_manager = get_engine_config_manager()
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥QPSã‚’å–å¾—
    if engine:
        engine_config = config_manager.get_engine(engine)
        if engine_config:
            min_interval = engine_config.min_interval
        else:
            min_interval = self._min_interval  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    else:
        min_interval = self._min_interval
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã®æœ€çµ‚æ¤œç´¢æ™‚åˆ»ã‚’è¿½è·¡
    engine_key = engine or "default"
    if engine_key not in self._last_search_times:
        self._last_search_times[engine_key] = 0
    
    elapsed = time.time() - self._last_search_times[engine_key]
    if elapsed < min_interval:
        await asyncio.sleep(min_interval - elapsed)
    
    self._last_search_times[engine_key] = time.time()
```

**æ³¨æ„ç‚¹**:
- `_last_search_times`ã‚’`dict[str, float]`ã«å¤‰æ›´ã—ã€ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã«è¿½è·¡
- `search()`ãƒ¡ã‚½ãƒƒãƒ‰ã§`_rate_limit(engine)`ã‚’å‘¼ã³å‡ºã™

---

## å•é¡Œ10: Toræ—¥æ¬¡åˆ©ç”¨ä¸Šé™ã®ãƒã‚§ãƒƒã‚¯ãŒæœªå®Ÿè£… âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-15  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: 
- `src/utils/schemas.py`: `TorUsageMetrics`, `DomainTorMetrics` Pydanticãƒ¢ãƒ‡ãƒ«è¿½åŠ 
- `src/utils/metrics.py`: `get_today_tor_metrics()`, `get_domain_tor_metrics()`, `record_request()`, `record_tor_usage()` ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ 
- `src/crawler/fetcher.py`: `_can_use_tor()` ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°è¿½åŠ ã€`fetch_url()` ã«æ—¥æ¬¡ä¸Šé™ãƒã‚§ãƒƒã‚¯çµ±åˆ

**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_tor_daily_limit_flow.py`  
**ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³**: `docs/sequences/tor_daily_limit_flow.md`

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/crawler/fetcher.py:1729` - `fetch_url()`ã§ã®Torä½¿ç”¨åˆ¤å®š
- `src/utils/policy_engine.py:496` - `PolicyEngine._adjust_domain_policy()`

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/crawler/fetcher.py:1729-1742
# Handle 403/429 - try Tor circuit renewal
if not result.ok and result.status in (403, 429) and not use_tor:
    logger.info("HTTP error, trying with Tor", url=url[:80], status=result.status)
    
    tor_controller = await get_tor_controller()
    if await tor_controller.renew_circuit(domain):
        result = await _http_fetcher.fetch(
            url,
            referer=context.get("referer"),
            use_tor=True,  # æ—¥æ¬¡ä¸Šé™ãƒã‚§ãƒƒã‚¯ãªã—
            ...
        )
```

### å•é¡Œç‚¹

1. **æ—¥æ¬¡åˆ©ç”¨ä¸Šé™ã®ãƒã‚§ãƒƒã‚¯ãªã—**: Torã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€æ—¥æ¬¡ã®åˆ©ç”¨ä¸Šé™ï¼ˆ`max_usage_ratio: 0.20`ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ãªã„
2. **åˆ©ç”¨çŠ¶æ³ã®è¿½è·¡ãªã—**: Torä½¿ç”¨å›æ•°ã‚„å‰²åˆã‚’è¿½è·¡ã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒãªã„
3. **ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¸Šé™ã®é©ç”¨ãªã—**: ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ã®`tor_usage_ratio`ã¯ã‚ã‚‹ãŒã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªæ—¥æ¬¡ä¸Šé™ã®ãƒã‚§ãƒƒã‚¯ãŒãªã„

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§4.3: "ãƒ‰ãƒ¡ã‚¤ãƒ³å˜ä½ã®Torç²˜ç€ï¼ˆ15åˆ†ï¼‰ã¨æ—¥æ¬¡ã®Toråˆ©ç”¨ä¸Šé™ï¼ˆå‰²åˆ/å›æ•°ï¼‰ã‚’é©ç”¨"
- Â§7: "Toråˆ©ç”¨ç‡: å…¨å–å¾—ã«å ã‚ã‚‹TorçµŒè·¯ã®å‰²åˆâ‰¤20%ï¼ˆæ—¥æ¬¡ä¸Šé™ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ä¸Šé™ã‚’ä¸¡æ–¹æº€ãŸã™ã“ã¨ï¼‰"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: Torã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€æ—¥æ¬¡ã®åˆ©ç”¨ä¸Šé™ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ä¸Šé™ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯Torã‚’ä½¿ç”¨ã—ãªã„

**å®Ÿè£…ç®‡æ‰€**:
- `src/crawler/fetcher.py:1729` - `fetch_url()`ã§ã®Torä½¿ç”¨åˆ¤å®š
- `src/utils/metrics.py` - Torä½¿ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½è·¡

**ä¿®æ­£æ¡ˆ**:
```python
# Torä½¿ç”¨å‰ã®ãƒã‚§ãƒƒã‚¯
async def _can_use_tor(domain: str | None = None) -> bool:
    """Check if Tor can be used based on daily limits.
    
    Per Â§4.3: Check both global daily limit and domain-specific limit.
    
    Args:
        domain: Optional domain for domain-specific check.
        
    Returns:
        True if Tor can be used.
    """
    from src.utils.metrics import get_metrics_collector
    from src.utils.config import get_settings
    
    settings = get_settings()
    max_usage_ratio = settings.tor.max_usage_ratio  # 0.20
    
    collector = get_metrics_collector()
    
    # Get today's Tor usage metrics
    today_metrics = collector.get_today_metrics()
    total_requests = today_metrics.get("total_requests", 0)
    tor_requests = today_metrics.get("tor_requests", 0)
    
    if total_requests == 0:
        return True  # No requests yet today
    
    # Check global daily limit
    current_ratio = tor_requests / total_requests
    if current_ratio >= max_usage_ratio:
        logger.debug(
            "Tor daily limit reached",
            current_ratio=current_ratio,
            max_ratio=max_usage_ratio,
        )
        return False
    
    # Check domain-specific limit if domain provided
    if domain:
        domain_metrics = collector.get_domain_metrics(domain)
        domain_total = domain_metrics.get("total_requests", 0)
        domain_tor = domain_metrics.get("tor_requests", 0)
        
        if domain_total > 0:
            domain_ratio = domain_tor / domain_total
            domain_policy = await get_domain_policy(domain)
            domain_max_ratio = domain_policy.tor_usage_ratio
            
            if domain_ratio >= domain_max_ratio:
                logger.debug(
                    "Tor domain limit reached",
                    domain=domain,
                    current_ratio=domain_ratio,
                    max_ratio=domain_max_ratio,
                )
                return False
    
    return True

# fetch_url()ã§ã®ä½¿ç”¨
if not result.ok and result.status in (403, 429) and not use_tor:
    if await _can_use_tor(domain):
        # Torä½¿ç”¨å¯èƒ½
        tor_controller = await get_tor_controller()
        if await tor_controller.renew_circuit(domain):
            result = await _http_fetcher.fetch(..., use_tor=True)
            # Torä½¿ç”¨ã‚’è¨˜éŒ²
            collector.record_tor_usage(domain)
    else:
        logger.info("Tor daily limit reached, skipping Tor escalation")
```

**æ³¨æ„ç‚¹**:
- Torä½¿ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½è·¡ã‚’`MetricsCollector`ã«è¿½åŠ 
- æ—¥æ¬¡ãƒªã‚»ãƒƒãƒˆã®å‡¦ç†ï¼ˆæ—¥ä»˜å¤‰æ›´æ™‚ã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆï¼‰
- ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®ä¸¡æ–¹ã®ä¸Šé™ã‚’ãƒã‚§ãƒƒã‚¯

---

## å•é¡Œ11: æ™‚é–“å¸¯ãƒ»æ—¥æ¬¡ã®äºˆç®—ä¸Šé™ãŒæœªå®Ÿè£… âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-15  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: 
- `src/utils/schemas.py`: `DomainDailyBudget`, `DomainBudgetCheckResult` Pydanticãƒ¢ãƒ‡ãƒ«è¿½åŠ 
- `src/scheduler/domain_budget.py`: `DomainDailyBudgetManager` ã‚¯ãƒ©ã‚¹æ–°è¦ä½œæˆ
- `src/utils/domain_policy.py`: `max_requests_per_day`, `max_pages_per_day` ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¿½åŠ 
- `config/domains.yaml`: æ—¥æ¬¡äºˆç®—è¨­å®šè¿½åŠ 
- `src/crawler/fetcher.py`: `fetch_url()` ã«æ—¥æ¬¡äºˆç®—ãƒã‚§ãƒƒã‚¯çµ±åˆ

**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_domain_daily_budget_flow.py`  
**ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³**: `docs/sequences/domain_daily_budget_flow.md`

### å®Ÿè£…å†…å®¹

#### ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥æ—¥æ¬¡äºˆç®—ä¸Šé™ï¼ˆIPã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ–ãƒ­ãƒƒã‚¯é˜²æ­¢ï¼‰

| è¨­å®š | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----|----------|-----|
| `max_requests_per_day` | 200 | ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã®æ—¥æ¬¡ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸Šé™ |
| `max_pages_per_day` | 100 | ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã®æ—¥æ¬¡ãƒšãƒ¼ã‚¸ä¸Šé™ |

#### ä¸»è¦æ©Ÿèƒ½

1. **æ—¥æ¬¡äºˆç®—ãƒã‚§ãƒƒã‚¯**: `fetch_url()` ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‰ã«äºˆç®—ãƒã‚§ãƒƒã‚¯
2. **è‡ªå‹•æ—¥ä»˜ãƒªã‚»ãƒƒãƒˆ**: æ—¥ä»˜å¤‰æ›´æ™‚ã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’è‡ªå‹•ãƒªã‚»ãƒƒãƒˆ
3. **ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥è¨­å®š**: `config/domains.yaml` ã§ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥ã®ä¸Šé™ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½
4. **ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒ—ãƒ³**: äºˆç®—ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¨±å¯

#### ä»•æ§˜æ›¸ã®è¦ä»¶ã¨ã®å¯¾å¿œ

- Â§4.3: "æ™‚é–“å¸¯ãƒ»æ—¥æ¬¡ã®äºˆç®—ä¸Šé™ã‚’è¨­å®š" â†’ **æ—¥æ¬¡äºˆç®—ã‚’å®Ÿè£…**
- Â§4.3: "æœŸé–“ãƒ»æ™‚é–“å¸¯ã®ã‚¹ãƒ­ãƒƒãƒˆåŒ–ï¼ˆå¤œé–“/ä¼‘æ—¥ã¯ä¿å®ˆçš„ï¼‰" â†’ **ã‚¹ã‚³ãƒ¼ãƒ—å¤–**ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡ç¤º: å¤œé–“/ä¼‘æ—¥ã®æ¦‚å¿µã¯ä¸è¦ã€IPãƒ–ãƒ­ãƒƒã‚¯é˜²æ­¢ãŒç›®çš„ï¼‰

### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
pytest tests/test_domain_budget.py -v

# ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python tests/scripts/debug_domain_daily_budget_flow.py
```

---

## å®Ÿè£…æ™‚æœŸ

Phase O.6å®Œäº†å¾Œã€åˆ¥ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè£…æ¨å¥¨ã€‚

## å•é¡Œ12: ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ãŒé©ç”¨ã•ã‚Œã¦ã„ãªã„ âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-11  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `src/crawler/fetcher.py:1896-1955` (fetch_url), `src/crawler/fetcher.py:1200-1250` (BrowserFetcher), `src/crawler/fetcher.py:509-710` (HTTPFetcher)  
**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_session_transfer_flow.py`

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/crawler/fetcher.py:1070` - `BrowserFetcher.fetch()`ã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒ—ãƒãƒ£
- `src/crawler/fetcher.py:1702` - `HTTPFetcher.fetch()`ã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨
- `src/crawler/fetcher.py:1605` - `fetch_url()`ã§ã®åˆå›ãƒ–ãƒ©ã‚¦ã‚¶â†’HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç§»è¡Œ

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/crawler/fetcher.py:1070-1120
async def fetch(self, url: str, ...):
    # ... ãƒ–ãƒ©ã‚¦ã‚¶ã§å–å¾— ...
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒ—ãƒãƒ£ã®å‡¦ç†ãŒãªã„
    # capture_browser_session()ãŒå‘¼ã°ã‚Œã¦ã„ãªã„
    
    return FetchResult(...)

# src/crawler/fetcher.py:1702-1708
async def fetch(self, url: str, ...):
    # HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§å–å¾—
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼ã®é©ç”¨ãŒãªã„
    # get_transfer_headers()ãŒå‘¼ã°ã‚Œã¦ã„ãªã„
    
    result = await _http_fetcher.fetch(url, ...)
```

### å•é¡Œç‚¹

1. **ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã‚­ãƒ£ãƒ—ãƒãƒ£ãªã—**: `BrowserFetcher.fetch()`ã§æˆåŠŸã—ãŸå–å¾—å¾Œã«ã€`capture_browser_session()`ãŒå‘¼ã°ã‚Œã¦ã„ãªã„
2. **HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨ãªã—**: `HTTPFetcher.fetch()`ã§ã€`get_transfer_headers()`ã‚’ä½¿ç”¨ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é©ç”¨ã—ã¦ã„ãªã„
3. **åˆå›ãƒ–ãƒ©ã‚¦ã‚¶â†’HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç§»è¡Œã®æœªå®Ÿè£…**: ä»•æ§˜ã§ã¯ã€Œåˆå›ã¯ãƒ–ãƒ©ã‚¦ã‚¶çµŒç”±ã€2å›ç›®ä»¥é™ã¯HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§304å†è¨ªã€ã¨ã‚ã‚‹ãŒã€ã“ã®ãƒ­ã‚¸ãƒƒã‚¯ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§3.1.2: "åˆå›å–å¾—ã®æŒ‡ç´‹æ•´åˆ: é™çš„ãƒšãƒ¼ã‚¸ã§ã‚ã£ã¦ã‚‚åˆå›ã‚¢ã‚¯ã‚»ã‚¹ã¯åŸå‰‡ãƒ–ãƒ©ã‚¦ã‚¶çµŒç”±ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ï¼‰ã§å®Ÿæ–½ã—ã€Cookie/ETag/LocalStorage/æŒ‡ç´‹ã‚’è‡ªç„¶ã«ç¢ºç«‹"
- Â§3.1.2: "2å›ç›®ä»¥é™ã¯HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆ`curl_cffi`ï¼‰ã§ETag/If-None-Matchãƒ»Last-Modified/If-Modified-Sinceã‚’æ´»ç”¨ã—è»½é‡å†è¨ª"
- Â§3.1.2: "ã‚»ãƒƒã‚·ãƒ§ãƒ³ç§»é€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£: åˆå›ãƒ–ãƒ©ã‚¦ã‚¶ã§ç¢ºç«‹ã—ãŸCookie/ETag/UA/Accept-Languageã‚’HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸å®‰å…¨ã«ç§»é€ï¼ˆåŒä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³é™å®šï¼‰"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: ãƒ–ãƒ©ã‚¦ã‚¶å–å¾—å¾Œã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã€HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå–å¾—æ™‚ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é©ç”¨ã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- `src/crawler/fetcher.py:1070` - `BrowserFetcher.fetch()`ã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒ—ãƒãƒ£
- `src/crawler/fetcher.py:1702` - `HTTPFetcher.fetch()`ã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨
- `src/crawler/fetcher.py:1605` - `fetch_url()`ã§ã®åˆå›ãƒ–ãƒ©ã‚¦ã‚¶â†’HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç§»è¡Œãƒ­ã‚¸ãƒƒã‚¯

**ä¿®æ­£æ¡ˆ**:
```python
# BrowserFetcher.fetch()ã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒ—ãƒãƒ£
async def fetch(self, url: str, ...):
    # ... æ—¢å­˜ã®å–å¾—å‡¦ç† ...
    
    if result.ok:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
        from src.crawler.session_transfer import capture_browser_session
        
        response_headers = {}
        if response:
            response_headers = dict(response.headers)
        
        session_id = await capture_browser_session(
            context,
            url,
            response_headers,
        )
        
        if session_id:
            logger.debug(
                "Captured browser session",
                url=url[:80],
                session_id=session_id,
            )
    
    return result

# HTTPFetcher.fetch()ã§ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼é©ç”¨
async def fetch(self, url: str, ...):
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å–å¾—
    from src.crawler.session_transfer import get_transfer_headers
    
    transfer_result = get_transfer_headers(url, include_conditional=True)
    
    if transfer_result.ok:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é©ç”¨
        if headers is None:
            headers = {}
        headers.update(transfer_result.headers)
        
        logger.debug(
            "Applied session transfer headers",
            url=url[:80],
            session_id=transfer_result.session_id,
        )
    
    # ... æ—¢å­˜ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç† ...
```

**æ³¨æ„ç‚¹**:
- åˆå›å–å¾—ã¯ãƒ–ãƒ©ã‚¦ã‚¶çµŒç”±ã€2å›ç›®ä»¥é™ã¯HTTPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆçµŒç”±ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦
- ã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ã¯åŒä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³é™å®šï¼ˆæ—¢ã«å®Ÿè£…æ¸ˆã¿ï¼‰
- ETag/Last-Modifiedã®æ¡ä»¶ä»˜ããƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å„ªå…ˆ

---

## å•é¡Œ13: ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ã‚¹ãƒ­ãƒƒãƒˆã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ãŒæœªå®Ÿè£… âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-15  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: 
- `src/search/browser_search_provider.py:400-575` (`_should_use_lastmile()`, `_select_lastmile_engine()`, `search()` ä¿®æ­£)
- `src/research/state.py:537-560` (`get_overall_harvest_rate()` è¿½åŠ )
- `src/utils/schemas.py:104-130` (`LastmileCheckResult` ãƒ¢ãƒ‡ãƒ«è¿½åŠ )
- `src/storage/schema.sql:253-264` (`lastmile_usage` ãƒ†ãƒ¼ãƒ–ãƒ«è¿½åŠ )

**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_lastmile_slot_flow.py`  
**ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³**: `docs/sequences/lastmile_slot_flow.md`

### å®Ÿè£…å†…å®¹

#### 1. `LastmileCheckResult` Pydanticãƒ¢ãƒ‡ãƒ«
```python
class LastmileCheckResult(BaseModel):
    should_use_lastmile: bool  # Whether to use lastmile engine
    reason: str                # Reason for decision
    harvest_rate: float        # Current harvest rate (0.0-1.0)
    threshold: float = 0.9     # Threshold for lastmile activation
```

#### 2. `ExplorationState.get_overall_harvest_rate()`
```python
def get_overall_harvest_rate(self) -> float:
    """Calculate overall harvest rate across all searches."""
    if not self._searches:
        return 0.0
    total_useful = sum(s.useful_fragments for s in self._searches.values())
    total_pages = sum(s.pages_fetched for s in self._searches.values())
    return total_useful / max(1, total_pages)
```

#### 3. `BrowserSearchProvider._should_use_lastmile()`
```python
def _should_use_lastmile(self, harvest_rate: float, threshold: float = 0.9) -> LastmileCheckResult:
    """Check if lastmile engine should be used based on harvest rate."""
    if harvest_rate >= threshold:
        return LastmileCheckResult(should_use_lastmile=True, ...)
    return LastmileCheckResult(should_use_lastmile=False, ...)
```

#### 4. `BrowserSearchProvider._select_lastmile_engine()`
- Circuit breaker ãƒã‚§ãƒƒã‚¯
- æ—¥æ¬¡ä½¿ç”¨åˆ¶é™ãƒã‚§ãƒƒã‚¯ (daily_limit)
- å³æ ¼ãª QPS åˆ¶é™é©ç”¨

#### 5. `search()` ãƒ¡ã‚½ãƒƒãƒ‰æ‹¡å¼µ
- `harvest_rate` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
- `harvest_rate >= 0.9` ã®å ´åˆã€ãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é¸æŠ

### å³æ ¼ãªåˆ¶å¾¡

| ã‚¨ãƒ³ã‚¸ãƒ³ | QPS | Daily Limit |
|---------|-----|-------------|
| brave | 0.1 | 50 |
| google | 0.05 | 10 |
| bing | 0.05 | 10 |

### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
pytest tests/test_browser_search_provider.py::TestLastmileSlotSelection -v

# å›åç‡ãƒ†ã‚¹ãƒˆ
pytest tests/test_research.py::TestGetOverallHarvestRate -v

# ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python tests/scripts/debug_lastmile_slot_flow.py
```

---

## å•é¡Œ14: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¥å…¨æ€§ç›£æŸ»ã®è‡ªå‹•å®Ÿè¡ŒãŒæœªå®Ÿè£… âœ… å®Ÿè£…å®Œäº†

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-11  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `src/crawler/fetcher.py:927-975`, `src/crawler/fetcher.py:877, 923`, `src/search/browser_search_provider.py:248-290`, `src/search/browser_search_provider.py:231`  
**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_profile_health_audit_flow.py`

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/crawler/fetcher.py:743` - `BrowserFetcher._ensure_browser()`ã§ã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
- `src/search/browser_search_provider.py:168` - `BrowserSearchProvider._ensure_browser()`ã§ã®ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
- `src/mcp/server.py:810` - `_handle_search()`ã§ã®ã‚¿ã‚¹ã‚¯é–‹å§‹æ™‚ï¼ˆå®Ÿè£…ä¸è¦: ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–æ™‚ã«è‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ï¼‰

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/crawler/fetcher.py:719-852
async def _ensure_browser(self, headful: bool = False, task_id: str | None = None):
    # ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
    browser, context = await self._get_browser_and_context(headful)
    
    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¥å…¨æ€§ç›£æŸ»ã®å‘¼ã³å‡ºã—ãŒãªã„
    # perform_health_check()ãŒå‘¼ã°ã‚Œã¦ã„ãªã„
```

### å•é¡Œç‚¹

1. **ã‚¿ã‚¹ã‚¯é–‹å§‹æ™‚ã®ç›£æŸ»ãªã—**: `_handle_search()`ã‚„`create_task()`ã§ã‚¿ã‚¹ã‚¯é–‹å§‹æ™‚ã«`perform_health_check()`ãŒå‘¼ã°ã‚Œã¦ã„ãªã„
2. **ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–æ™‚ã®ç›£æŸ»ãªã—**: `_ensure_browser()`ã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–æ™‚ã«`perform_health_check()`ãŒå‘¼ã°ã‚Œã¦ã„ãªã„
3. **å®šæœŸæ¤œæŸ»ã®æœªå®Ÿè£…**: UAãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è¿½å¾“ã¨ãƒ•ã‚©ãƒ³ãƒˆã‚»ãƒƒãƒˆã®ä¸€è²«æ€§ã®å®šæœŸæ¤œæŸ»ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§4.3.1: "é«˜é »åº¦ãƒã‚§ãƒƒã‚¯: ã‚¿ã‚¹ã‚¯é–‹å§‹æ™‚ãŠã‚ˆã³ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–æ™‚ã«UA/ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€ãƒ•ã‚©ãƒ³ãƒˆã‚»ãƒƒãƒˆã€è¨€èª/ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³ã€Canvas/AudioæŒ‡ç´‹ã®å·®åˆ†æ¤œçŸ¥ã‚’å®Ÿè¡Œ"
- Â§4.3: "UAãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®è¿½å¾“ã¨ãƒ•ã‚©ãƒ³ãƒˆã‚»ãƒƒãƒˆã®ä¸€è²«æ€§ã‚’å®šæœŸæ¤œæŸ»ï¼ˆå·®åˆ†æ¤œçŸ¥æ™‚ã¯è‡ªå‹•ä¿®æ­£ï¼‰"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: ã‚¿ã‚¹ã‚¯é–‹å§‹æ™‚ã¨ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–æ™‚ã«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¥å…¨æ€§ç›£æŸ»ã‚’è‡ªå‹•å®Ÿè¡Œã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- `src/crawler/fetcher.py:719` - `BrowserFetcher._ensure_browser()`
- `src/search/browser_search_provider.py:168` - `BrowserSearchProvider._ensure_browser()`
- `src/mcp/server.py:810` - `_handle_search()`ã§ã®ã‚¿ã‚¹ã‚¯é–‹å§‹æ™‚

**å®Ÿè£…å†…å®¹**:
- `BrowserFetcher._perform_health_audit()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ ï¼ˆ`src/crawler/fetcher.py:927-975`ï¼‰
- `BrowserFetcher._ensure_browser()`å†…ã§ã€contextä½œæˆå¾Œã«`_perform_health_audit()`ã‚’å‘¼ã³å‡ºã—ï¼ˆheadful/headlessä¸¡æ–¹ï¼‰
- `BrowserSearchProvider._perform_health_audit()`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ ï¼ˆ`src/search/browser_search_provider.py:248-290`ï¼‰
- `BrowserSearchProvider._ensure_browser()`å†…ã§ã€æ–°ã—ã„contextä½œæˆæ™‚ã«`_perform_health_audit()`ã‚’å‘¼ã³å‡ºã—

**å®Ÿè£…ã®ç‰¹å¾´**:
- ç›£æŸ»ã¯æœ€å°é™ã®ãƒšãƒ¼ã‚¸ï¼ˆ`about:blank`ï¼‰ã§å®Ÿè¡Œã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿ã‚’æœ€å°åŒ–
- è‡ªå‹•ä¿®å¾©ãŒæœ‰åŠ¹ãªå ´åˆã€ä¿®å¾©å¾Œã«å†ç›£æŸ»ã‚’å®Ÿè¡Œ
- ç›£æŸ»ãƒ­ã‚°ã‚’æ§‹é€ åŒ–è¨˜éŒ²
- ç›£æŸ»å¤±æ•—æ™‚ã‚‚éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã§é€šå¸¸ãƒ•ãƒ­ãƒ¼ã‚’ç¶™ç¶š
- `BrowserSearchProvider`ã§ã¯ã€æ—¢å­˜ã®contextã‚’å†åˆ©ç”¨ã™ã‚‹å ´åˆã¯ç›£æŸ»ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ–°ã—ã„contextä½œæˆæ™‚ã®ã¿å®Ÿè¡Œï¼‰

---

## å•é¡Œ15: ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ©ã‚¤ã‚¯æ“ä½œã®å®Œå…¨ãªé©ç”¨ãŒæœªå®Ÿè£… âœ… å®Ÿè£…å®Œäº†

---

## å•é¡Œ16: ã‚¨ãƒ³ã‚¸ãƒ³æ­£è¦åŒ–ãƒ¬ã‚¤ãƒ¤ãŒæœªå®Ÿè£…

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/search/browser_search_provider.py` - `BrowserSearchProvider.search()`ã§ã®ã‚¯ã‚¨ãƒªæ­£è¦åŒ–
- `src/search/search_api.py` - `search_serp()`ã§ã®ã‚¯ã‚¨ãƒªæ­£è¦åŒ–
- æ–°è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: `src/search/query_normalizer.py`ï¼ˆæ–°è¦ä½œæˆï¼‰

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/search/browser_search_provider.py
# ã‚¯ã‚¨ãƒªã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã®æ­£è¦åŒ–ãªã—ï¼‰
search_url = parser.build_search_url(query)
```

```yaml
# config/engines.yaml
operator_mapping:
  site:
    default: "site:{domain}"
    google: "site:{domain}"
    bing: "site:{domain}"
    # ... å®šç¾©ã¯ã‚ã‚‹ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„
```

### å•é¡Œç‚¹

1. **ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã®æ¼”ç®—å­å¯¾å¿œå·®ãŒå¸åã•ã‚Œã¦ã„ãªã„**: å„ã‚¨ãƒ³ã‚¸ãƒ³ã§æ¼”ç®—å­ï¼ˆ`site:`, `filetype:`, `intitle:`ç­‰ï¼‰ã®æ§‹æ–‡ãŒç•°ãªã‚‹ãŒã€çµ±ä¸€çš„ãªæ­£è¦åŒ–å‡¦ç†ãŒãªã„
2. **æœŸé–“æŒ‡å®šã®å¯¾å¿œå·®ãŒå¸åã•ã‚Œã¦ã„ãªã„**: `after:`ã‚„`before:`ãªã©ã®æœŸé–“æŒ‡å®šãŒã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã£ã¦ç•°ãªã‚‹ãŒã€æ­£è¦åŒ–å‡¦ç†ãŒãªã„
3. **ãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œç´¢ã®å¯¾å¿œå·®ãŒå¸åã•ã‚Œã¦ã„ãªã„**: å¼•ç”¨ç¬¦ï¼ˆ`"..."`ï¼‰ã®æ‰±ã„ãŒã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã£ã¦ç•°ãªã‚‹ãŒã€æ­£è¦åŒ–å‡¦ç†ãŒãªã„
4. **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®`operator_mapping`ãŒæœªä½¿ç”¨**: `config/engines.yaml`ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ãŒã€å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã§ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§3.1.1: "ã‚¨ãƒ³ã‚¸ãƒ³æ­£è¦åŒ–ãƒ¬ã‚¤ãƒ¤: ãƒ•ãƒ¬ãƒ¼ã‚º/æ¼”ç®—å­/æœŸé–“æŒ‡å®šç­‰ã®å¯¾å¿œå·®ã‚’å¸åã™ã‚‹ã‚¯ã‚¨ãƒªæ­£è¦åŒ–ã‚’å®Ÿè£…ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã«æœ€é©åŒ–ï¼‰"
- Â§3.1.4: "ã‚¨ãƒ³ã‚¸ãƒ³æ­£è¦åŒ–: ã‚¯ã‚¨ãƒªæ­£è¦åŒ–: æ¼”ç®—å­ãƒ»æœŸé–“æŒ‡å®šãƒ»å¼•ç”¨ãƒ»`site:` ã®ã‚¨ãƒ³ã‚¸ãƒ³å·®ã‚’å¸åã™ã‚‹ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é©ç”¨"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ã®ã‚¯ã‚¨ãƒªæ­£è¦åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å®Ÿè£…ã—ã€`config/engines.yaml`ã®`operator_mapping`ã‚’æ´»ç”¨ã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- æ–°è¦: `src/search/query_normalizer.py` - ã‚¯ã‚¨ãƒªæ­£è¦åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- `src/search/browser_search_provider.py` - `search()`ãƒ¡ã‚½ãƒƒãƒ‰ã§æ­£è¦åŒ–ã‚’é©ç”¨
- `src/search/search_api.py` - `search_serp()`ã§æ­£è¦åŒ–ã‚’é©ç”¨

**ä¿®æ­£æ¡ˆ**:

```python
# src/search/query_normalizer.pyï¼ˆæ–°è¦ä½œæˆï¼‰
from typing import Optional
from src.search.engine_config import get_engine_config_manager

class QueryNormalizer:
    """Normalize search queries for different engines."""
    
    def __init__(self):
        self.config_manager = get_engine_config_manager()
    
    def normalize(self, query: str, engine: str) -> str:
        """Normalize query for specific engine.
        
        Args:
            query: Original query string
            engine: Target engine name
            
        Returns:
            Normalized query string
        """
        config = self.config_manager.get_config()
        mapping = config.operator_mapping
        
        # æ¼”ç®—å­ã®æ­£è¦åŒ–
        normalized = query
        
        # site:æ¼”ç®—å­ã®æ­£è¦åŒ–
        if "site:" in normalized:
            site_pattern = r'site:(\S+)'
            matches = re.findall(site_pattern, normalized)
            for domain in matches:
                engine_syntax = mapping.get("site", {}).get(engine, mapping.get("site", {}).get("default", f"site:{domain}"))
                normalized = normalized.replace(f"site:{domain}", engine_syntax.format(domain=domain))
        
        # filetype:æ¼”ç®—å­ã®æ­£è¦åŒ–
        if "filetype:" in normalized:
            filetype_pattern = r'filetype:(\S+)'
            matches = re.findall(filetype_pattern, normalized)
            for filetype in matches:
                engine_syntax = mapping.get("filetype", {}).get(engine, mapping.get("filetype", {}).get("default", f"filetype:{filetype}"))
                normalized = normalized.replace(f"filetype:{filetype}", engine_syntax.format(type=filetype))
        
        # intitle:æ¼”ç®—å­ã®æ­£è¦åŒ–ï¼ˆå¯¾å¿œã‚¨ãƒ³ã‚¸ãƒ³ã®ã¿ï¼‰
        if "intitle:" in normalized:
            intitle_pattern = r'intitle:(\S+)'
            matches = re.findall(intitle_pattern, normalized)
            for text in matches:
                if engine in mapping.get("intitle", {}):
                    engine_syntax = mapping.get("intitle", {}).get(engine)
                    normalized = normalized.replace(f"intitle:{text}", engine_syntax.format(text=text))
                else:
                    # å¯¾å¿œã—ã¦ã„ãªã„ã‚¨ãƒ³ã‚¸ãƒ³ã§ã¯å‰Šé™¤ã¾ãŸã¯è­¦å‘Š
                    logger.warning(f"Engine {engine} does not support intitle: operator")
                    normalized = normalized.replace(f"intitle:{text}", text)
        
        # æœŸé–“æŒ‡å®šã®æ­£è¦åŒ–ï¼ˆafter:, before:ï¼‰
        if "after:" in normalized:
            after_pattern = r'after:(\S+)'
            matches = re.findall(after_pattern, normalized)
            for date in matches:
                if engine in mapping.get("date_after", {}):
                    engine_syntax = mapping.get("date_after", {}).get(engine)
                    if engine_syntax:
                        normalized = normalized.replace(f"after:{date}", engine_syntax.format(date=date))
                else:
                    # å¯¾å¿œã—ã¦ã„ãªã„ã‚¨ãƒ³ã‚¸ãƒ³ã§ã¯å‰Šé™¤ã¾ãŸã¯è­¦å‘Š
                    logger.warning(f"Engine {engine} does not support after: operator")
                    normalized = normalized.replace(f"after:{date}", "")
        
        # å¼•ç”¨ç¬¦ã®æ­£è¦åŒ–ï¼ˆãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œç´¢ï¼‰
        if '"' in normalized:
            # ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã£ã¦å¼•ç”¨ç¬¦ã®æ‰±ã„ãŒç•°ãªã‚‹å ´åˆã®æ­£è¦åŒ–
            # ç¾çŠ¶ã¯ãã®ã¾ã¾ä½¿ç”¨ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³ãŒå¯¾å¿œã—ã¦ã„ã‚‹ã¨ä»®å®šï¼‰
            pass
        
        return normalized
```

**ä½¿ç”¨ä¾‹**:

```python
# src/search/browser_search_provider.py
from src.search.query_normalizer import QueryNormalizer

normalizer = QueryNormalizer()

# ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠå¾Œã€ã‚¯ã‚¨ãƒªã‚’æ­£è¦åŒ–
normalized_query = normalizer.normalize(query, engine)
search_url = parser.build_search_url(normalized_query)
```

**æ³¨æ„ç‚¹**:
- `config/engines.yaml`ã®`operator_mapping`ã‚’æ´»ç”¨
- ã‚¨ãƒ³ã‚¸ãƒ³ãŒå¯¾å¿œã—ã¦ã„ãªã„æ¼”ç®—å­ã¯å‰Šé™¤ã¾ãŸã¯è­¦å‘Šãƒ­ã‚°ã‚’å‡ºåŠ›
- æ­£è¦åŒ–å¤±æ•—ç‡ãŒé–¾å€¤è¶…éã®å ´åˆã¯ã‚¨ãƒ³ã‚¸ãƒ³ã‚’è‡ªå‹•é™æ ¼ï¼ˆÂ§3.1.4æº–æ‹ ï¼‰
- éäº’æ›æ¤œçŸ¥: æ­£è¦åŒ–å¤±æ•—ç‡ãŒé–¾å€¤è¶…éã§å½“è©²ã‚¨ãƒ³ã‚¸ãƒ³ã‚’è‡ªå‹•é™æ ¼ï¼ˆé‡ã¿ä½ä¸‹ï¼‰ã—ãƒ­ã‚°ã‚’æ®‹ã™

**å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—**:
1. `src/search/query_normalizer.py`ã‚’ä½œæˆ
2. `config/engines.yaml`ã®`operator_mapping`ã‚’èª­ã¿è¾¼ã‚€å‡¦ç†ã‚’å®Ÿè£…
3. å„æ¼”ç®—å­ã®æ­£è¦åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
4. `BrowserSearchProvider.search()`ã§æ­£è¦åŒ–ã‚’é©ç”¨
5. `search_api.search_serp()`ã§æ­£è¦åŒ–ã‚’é©ç”¨
6. æ­£è¦åŒ–å¤±æ•—ç‡ã®ç›£è¦–ã¨ã‚¨ãƒ³ã‚¸ãƒ³é™æ ¼ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…

---

**å®Ÿè£…å®Œäº†æ—¥**: 2025-12-11  
**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**: `src/crawler/fetcher.py:1360-1382`, `src/search/browser_search_provider.py:385-410`  
**æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: `tests/scripts/debug_human_behavior_flow.py`

### å½±éŸ¿ç¯„å›²

**å½±éŸ¿ç®‡æ‰€**:
- `src/crawler/fetcher.py:1360` - `BrowserFetcher.fetch()`ã§ã®ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ©ã‚¤ã‚¯æ“ä½œ
- `src/search/browser_search_provider.py:385` - `BrowserSearchProvider.search()`ã§ã®ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ©ã‚¤ã‚¯æ“ä½œ

### ç¾çŠ¶ã®å®Ÿè£…

```python
# src/crawler/fetcher.py:1124-1126
# Simulate human reading behavior
if simulate_human:
    await self._human_behavior.simulate_reading(page, len(content_bytes))
# ãƒã‚¦ã‚¹è»Œè·¡ã€ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒªã‚ºãƒ ã€ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ…£æ€§ã®é©ç”¨ãŒãªã„
```

### å•é¡Œç‚¹

1. **ãƒã‚¦ã‚¹è»Œè·¡ã®é©ç”¨ãªã—**: `HumanBehaviorSimulator.move_mouse()`ã‚„`move_to_element()`ãŒå®Ÿéš›ã«å‘¼ã°ã‚Œã¦ã„ãªã„
2. **ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒªã‚ºãƒ ã®é©ç”¨ãªã—**: `HumanBehaviorSimulator.type_text()`ãŒå®Ÿéš›ã«å‘¼ã°ã‚Œã¦ã„ãªã„
3. **ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ…£æ€§ã®é©ç”¨ãŒä¸å®Œå…¨**: `simulate_reading()`ã¯å‘¼ã°ã‚Œã¦ã„ã‚‹ãŒã€`InertialScroll`ã®å®Œå…¨ãªæ©Ÿèƒ½ãŒé©ç”¨ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹

### ä»•æ§˜æ›¸ã®è¦ä»¶

- Â§4.3.4: "ãƒã‚¦ã‚¹è»Œè·¡è‡ªç„¶åŒ–: Bezieræ›²ç·šã«ã‚ˆã‚‹è‡ªç„¶ãªè»Œè·¡ç”Ÿæˆã€å¾®ç´°ãªã‚¸ãƒƒã‚¿ãƒ¼ä»˜ä¸"
- Â§4.3.4: "ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒªã‚ºãƒ : ã‚¬ã‚¦ã‚¹åˆ†å¸ƒãƒ™ãƒ¼ã‚¹ã®é…å»¶ã€å¥èª­ç‚¹å¾Œã®é•·ã„é–“ã€ç¨€ãªã‚¿ã‚¤ãƒæ¨¡å€£"
- Â§4.3.4: "ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ…£æ€§: æ…£æ€§ä»˜ãã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã€easingé–¢æ•°ã«ã‚ˆã‚‹è‡ªç„¶ãªæ¸›é€Ÿ"
- Â§4.3: "ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ©ã‚¤ã‚¯æ“ä½œ: ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã•ã‚ŒãŸè¦–ç·šç§»å‹•/ãƒ›ã‚¤ãƒ¼ãƒ«æ…£æ€§/å¾…æ©Ÿæ™‚é–“åˆ†å¸ƒã‚’é©ç”¨ï¼ˆCDPã§åˆ¶å¾¡ï¼‰"

### ä¿®æ­£ææ¡ˆ

**æ–¹é‡**: ãƒšãƒ¼ã‚¸ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ™‚ã«ãƒã‚¦ã‚¹è»Œè·¡ã€ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒªã‚ºãƒ ã€ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ…£æ€§ã‚’å®Œå…¨ã«é©ç”¨ã™ã‚‹

**å®Ÿè£…ç®‡æ‰€**:
- `src/crawler/fetcher.py:1124` - `BrowserFetcher.fetch()`
- `src/search/browser_search_provider.py` - `BrowserSearchProvider.search()`

**ä¿®æ­£æ¡ˆ**:
```python
# BrowserFetcher.fetch()ã§ã®ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ©ã‚¤ã‚¯æ“ä½œã®å®Œå…¨é©ç”¨
if simulate_human:
    # ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ…£æ€§ã‚’é©ç”¨
    await self._human_behavior.simulate_reading(page, len(content_bytes))
    
    # ãƒã‚¦ã‚¹è»Œè·¡ã‚’é©ç”¨ï¼ˆãƒšãƒ¼ã‚¸å†…ã®ä¸»è¦è¦ç´ ã«ç§»å‹•ï¼‰
    try:
        # ãƒšãƒ¼ã‚¸å†…ã®ä¸»è¦ãƒªãƒ³ã‚¯ã‚„è¦ç´ ã«ãƒã‚¦ã‚¹ã‚’ç§»å‹•
        links = await page.query_selector_all("a, button, input")
        if links:
            target_link = random.choice(links[:5])  # æœ€åˆã®5ã¤ã‹ã‚‰é¸æŠ
            await self._human_behavior.move_to_element(page, target_link)
    except Exception as e:
        logger.debug("Mouse movement skipped", error=str(e))
    
    # ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒªã‚ºãƒ ã¯æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ã‚„å…¥åŠ›æ¬„ãŒã‚ã‚‹å ´åˆã«é©ç”¨
    # ï¼ˆç¾åœ¨ã®fetch()ã§ã¯é€šå¸¸ã¯ä¸è¦ï¼‰
```

**æ³¨æ„ç‚¹**:
- ãƒã‚¦ã‚¹è»Œè·¡ã¯ãƒšãƒ¼ã‚¸å†…ã®ä¸»è¦è¦ç´ ï¼ˆãƒªãƒ³ã‚¯ã€ãƒœã‚¿ãƒ³ï¼‰ã«é©ç”¨
- ã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãƒªã‚ºãƒ ã¯æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ã‚„å…¥åŠ›æ¬„ãŒã‚ã‚‹å ´åˆã«ã®ã¿é©ç”¨
- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ…£æ€§ã¯`simulate_reading()`ã§æ—¢ã«é©ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã€å®Œå…¨æ€§ã‚’ç¢ºèª

---

**å„ªå…ˆé †ä½**:
1. ~~å•é¡Œ3ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å†åˆ©ç”¨ï¼‰~~ âœ… å®Œäº†
2. ~~å•é¡Œ5ï¼ˆstart_sessionã§ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‹ãï¼‰~~ âœ… å®Œäº†
3. ~~å•é¡Œ12ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³è»¢é€ã®é©ç”¨ï¼‰~~ âœ… å®Œäº†
4. ~~å•é¡Œ14ï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¥å…¨æ€§ç›£æŸ»ã®è‡ªå‹•å®Ÿè¡Œï¼‰~~ âœ… å®Œäº†
5. ~~å•é¡Œ15ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ©ã‚¤ã‚¯æ“ä½œã®å®Œå…¨ãªé©ç”¨ï¼‰~~ âœ… å®Œäº†
6. ~~å•é¡Œ8ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³é¸æŠãƒ­ã‚¸ãƒƒã‚¯ + å‹•çš„é‡ã¿å­¦ç¿’ï¼‰~~ âœ… å®Œäº†
7. ~~å•é¡Œ13ï¼ˆãƒ©ã‚¹ãƒˆãƒã‚¤ãƒ«ã‚¹ãƒ­ãƒƒãƒˆåˆ¤å®šï¼‰~~ âœ… å®Œäº†
8. ~~å•é¡Œ9ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³åˆ¥QPSåˆ¶é™ï¼‰~~ âœ… å®Œäº†
9. ~~å•é¡Œ16ï¼ˆã‚¨ãƒ³ã‚¸ãƒ³æ­£è¦åŒ–ãƒ¬ã‚¤ãƒ¤ï¼‰~~ âœ… å®Ÿè£…æ¸ˆã¿ï¼ˆ`transform_query_for_engine`ï¼‰
10. ~~å•é¡Œ10ï¼ˆToræ—¥æ¬¡åˆ©ç”¨ä¸Šé™ï¼‰~~ âœ… å®Œäº†ï¼ˆ2025-12-15ï¼‰
11. ~~å•é¡Œ11ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¥æ—¥æ¬¡äºˆç®—ä¸Šé™ï¼‰~~ âœ… å®Œäº†ï¼ˆ2025-12-15ï¼‰
12. ~~å•é¡Œ4, 6, 7ï¼ˆè¦ç¢ºèªäº‹é …ã®ç¢ºèªï¼‰~~ âœ… ç¢ºèªå®Œäº†ï¼ˆ2025-12-15ï¼‰

