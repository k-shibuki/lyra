# Lyra Environment Configuration
# Copy this file to .env and modify as needed.
# .env is gitignored and will not be committed.
#
# Environment variables override settings.yaml values.
# Format: LYRA_<SECTION>__<KEY>=value (double underscore for nesting)

# =============================================================================
# HYBRID MODE (WSL + Container)
# =============================================================================
# MCP server runs on WSL host, LLM/ML accessed via proxy container

# Proxy URL for hybrid mode (lyra container proxy server)
# LYRA_GENERAL__PROXY_URL=http://localhost:8080

# =============================================================================
# USER-SPECIFIC SETTINGS
# =============================================================================

# Chrome CDP connection (WSL2 -> Windows Chrome)
# Dynamic Worker Pool: Each worker gets its own Chrome instance
# Worker N connects to BASE_PORT + N (e.g., Worker 0 -> 9222, Worker 1 -> 9223)
# LYRA_BROWSER__CHROME_HOST=localhost
# LYRA_BROWSER__CHROME_BASE_PORT=9222
# LYRA_BROWSER__CHROME_PROFILE_PREFIX=Lyra-

# =============================================================================
# CONTAINER NETWORKING (Internal services)
# =============================================================================

# Ollama LLM server (container name - accessed via proxy)
# LYRA_LLM__OLLAMA_HOST=http://ollama:11434

# Tor SOCKS proxy (container name)
# LYRA_TOR__SOCKS_HOST=tor
# LYRA_TOR__SOCKS_PORT=9050
# LYRA_TOR__CONTROL_PORT=9051

# ML Server (internal network - lyra-internal)
# LYRA_ML__SERVER_URL=http://lyra-ml:8100

# =============================================================================
# ML SERVER SETTINGS (for lyra-ml container)
# =============================================================================

# Model names (defaults shown, uncomment to override)
# LYRA_ML__EMBEDDING_MODEL=BAAI/bge-m3
# LYRA_ML__RERANKER_MODEL=BAAI/bge-reranker-v2-m3
# LYRA_ML__NLI_MODEL=cross-encoder/nli-deberta-v3-small

# =============================================================================
# SCRIPT SETTINGS (for scripts/*.sh)
# =============================================================================

# Container name (used by all scripts)
# LYRA_SCRIPT__CONTAINER_NAME=lyra

# Container startup timeout in seconds
# LYRA_SCRIPT__CONTAINER_TIMEOUT=30

# Test completion detection threshold in seconds
# LYRA_SCRIPT__COMPLETION_THRESHOLD=5

# =============================================================================
# MAKE COMMANDS OUTPUT MODE
# =============================================================================

# JSON output for AI agents (affects all make commands)
# Set to "true" for machine-readable JSON output
# LYRA_OUTPUT_JSON=false

# =============================================================================
# TEST SAFETY SETTINGS
# =============================================================================

# Test layer for pytest (controls external service access)
# Values: unit, integration, e2e (default: not set = unit/integration)
# Only e2e tests can access external search services
# LYRA_TEST_LAYER=e2e

# Override: allow external search during pytest (DANGEROUS - may cause IP blocking)
# Only set this if you know what you're doing
# LYRA_ALLOW_EXTERNAL_SEARCH=1

# =============================================================================
# OPTIONAL SETTINGS
# =============================================================================

# Session tags (prompt injection defense)
# Default: enabled. Set to false to disable.
# LYRA_LLM__SESSION_TAGS_ENABLED=false

# Log level: DEBUG, INFO, WARNING, ERROR
# LYRA_GENERAL__LOG_LEVEL=INFO
