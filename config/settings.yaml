# Lyra - Local Yielding Research Aide
# Main Configuration File

# === General Settings ===
general:
  project_name: "lyra"
  version: "0.1.0"
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  data_dir: "data"
  logs_dir: "logs"
  
# === Task Limits ===
task_limits:
  budget_pages_per_task: 250
  max_time_minutes_gpu: 60
  max_time_minutes_cpu: 60
  llm_time_ratio_max: 0.30  # LLM processing ≤30%
  max_manual_interventions: 3
  max_manual_intervention_time_minutes: 5
  # Per-search timeout for safe pipeline stop (ADR-0002)
  # 300s allows: Academic API + SERP + identifier processing + web page fetch + claim extraction
  search_timeout_seconds: 300

# === Search Settings ===
search:
  # BrowserSearchProvider is used for all searches (direct Playwright search)
  use_browser: true
  default_engine: "duckduckgo"  # Default search engine for browser provider
  
  initial_query_count_gpu: 12  # 10-16
  initial_query_count_cpu: 10  # 8-12
  results_per_query: 7  # 5-10
  exploration_depth: 3  # Standard 3, max 4 for high-value branches
  max_exploration_depth: 4
  # Saturation criteria
  min_independent_sources: 3
  min_primary_secondary_sources: 2  # 1 primary + 1 secondary
  # Novelty criteria
  novelty_threshold: 0.10  # <10% new for 2 cycles → stop
  novelty_cycles_to_stop: 2

  # Claims extraction scope - controls LLM usage for claim extraction
  # "authoritative": Only gov/edu/academic sources (minimal LLM, fastest)
  # "reputable": + research orgs, major news, .org domains (balanced)
  # "all": All sources including blogs/forums (max LLM usage, slowest)
  claims_extraction_scope: "reputable"

  # Citation graph integration
  citation_graph_top_n_papers: 5
  citation_graph_depth: 1
  citation_graph_direction: "both"  # references, citations, both
  citation_filter:
    # Stage 0: metadata filter (0 = no threshold)
    min_citation_count: 0

    # Stage 1: embedding + impact_score (citation_count-based, source-agnostic)
    stage1_top_k: 30
    stage1_weight_embedding: 0.5
    stage1_weight_impact: 0.5

    # Stage 2: LLM evidence-usefulness + Stage 1 signals
    stage2_top_k: 10
    stage2_weight_llm: 0.5
    stage2_weight_embedding: 0.3
    stage2_weight_impact: 0.2

    # Prompt/input limits
    max_source_abstract_chars: 1200
    max_target_abstract_chars: 1200
    llm_timeout_seconds: 60.0
    llm_max_tokens: 16

  # General web citation detection (LLM YES/NO classification for outbound links)
  # Controls LLM cost and DB growth. Set max_* to 0 for "no limit".
  web_citation_detection:
    enabled: true
    run_on_primary_sources_only: true
    require_useful_text: true
    min_text_chars: 200
    max_candidates_per_page: 10
    max_edges_per_page: 0
    budget_pages_per_task: 0
    create_placeholder_pages: true

# === Crawler Settings ===
crawler:
  # Rate limiting
  engine_qps: 0.25  # 1 req/4s
  domain_qps: 0.2   # 1 req/5s
  domain_concurrent: 1
  network_concurrent: 4  # 3-5
  
  # Timeouts (seconds)
  request_timeout: 30
  page_load_timeout: 45
  
  # Retry settings
  max_retries: 3
  backoff_base: 2.0
  backoff_max: 120
  
  # Cooldown
  domain_cooldown_minutes: 60
  
  # User agent delay (random)
  delay_min: 1.5
  delay_max: 5.5
  
  # BFS depth for same domain
  same_domain_depth: 2
  
  # Wayback Machine fallback timeout (seconds)
  # Reduced from 30s - blocked URLs rarely have useful Wayback archives
  wayback_timeout: 10

# === Tor Settings ===
tor:
  enabled: true
  socks_host: "127.0.0.1"
  socks_port: 9050
  control_port: 9051
  circuit_sticky_minutes: 15
  max_usage_ratio: 0.20  # Tor usage ≤20%
  # Only use Tor when blocked
  default_route: "direct"  # direct, tor
  
  # === DNS Policy (§4.3) ===
  dns:
    # Resolve DNS through Tor SOCKS proxy (socks5h://) when using Tor route
    # This prevents DNS leaks by ensuring DNS queries go through Tor
    resolve_through_tor: true
    
    # Disable EDNS Client Subnet (ECS) to prevent location leakage
    # Note: This is handled at the resolver level, set to true to request
    # ECS-disabled resolution where supported
    disable_edns_client_subnet: true
    
    # Respect DNS cache TTL to reduce exposure from frequent re-resolution
    respect_cache_ttl: true
    
    # Minimum cache TTL in seconds (even if DNS returns lower)
    min_cache_ttl: 60
    
    # Maximum cache TTL in seconds (cap very long TTLs)
    max_cache_ttl: 3600
    
    # Enable DNS leak detection metrics
    leak_detection_enabled: true

# === IPv6 Settings (§4.3) ===
ipv6:
  # Enable/disable IPv6 globally
  enabled: true
  # Default preference: ipv6_first, ipv4_first, auto
  preference: "ipv6_first"
  # Timeout before falling back to alternative address family (seconds)
  fallback_timeout: 5.0
  # Success rate threshold below which IPv6 will be disabled for a domain
  learning_threshold: 0.3
  # Minimum samples required before adjusting preferences
  min_samples: 5
  # EMA alpha for success rate updates (higher = faster adaptation)
  ema_alpha: 0.1

# === HTTP/3 (QUIC) Settings (§4.3) ===
http3:
  # Enable HTTP/3 policy tracking
  enabled: true
  # EMA alpha for behavioral difference updates
  ema_alpha: 0.1
  # Behavioral difference threshold to trigger browser ratio boost
  # When browser success rate exceeds HTTP client by this much, boost browser ratio
  difference_threshold: 0.15
  # Maximum browser ratio boost from HTTP/3 policy
  max_browser_boost: 0.3
  # Minimum samples required before adjusting browser ratio
  min_samples: 5

# === Browser Settings ===
browser:
  # Chrome remote debugging - Dynamic Worker Pool
  # Each worker gets its own Chrome instance: Worker N -> BASE_PORT + N
  # WSL2 mirrored networking allows direct localhost access from WSL to Windows Chrome
  chrome_host: "localhost"
  chrome_base_port: 9222  # Worker 0 = 9222, Worker 1 = 9223, etc.
  chrome_profile_prefix: "Lyra-"  # Profile names: Lyra-00, Lyra-01, etc.
  
  # Headless/Headful
  default_headless: true
  headful_ratio_initial: 0.1
  
  # Resource blocking
  block_ads: true
  block_trackers: true
  block_large_media: true
  
  # Viewport
  viewport_width: 1920
  viewport_height: 1080
  
  # Undetected ChromeDriver settings (fallback for Cloudflare/Turnstile)
  undetected_chromedriver:
    enabled: true
    # Auto-escalate to undetected when captcha_rate exceeds this threshold
    auto_escalate_captcha_rate: 0.5
    # Auto-escalate when block_score exceeds this threshold
    auto_escalate_block_score: 5
    # Cloudflare bypass timeout (seconds)
    cloudflare_timeout: 45
    # Use headless mode (less effective for bypass, but faster)
    prefer_headless: false

# === LLM Settings (Ollama) ===
llm:
  ollama_host: "http://localhost:11434"
  
  # LLM model for extraction tasks
  # 3B: lighter, 7B: better instruction following for complex prompts
  # Set via LYRA_LLM__MODEL in .env (Single Source of Truth)
  # model: "qwen2.5:3b"
  model_context: 4096
  
  # Temperature
  temperature: 0.3
  
  # GPU settings
  gpu_layers: -1  # All layers on GPU

# === Embedding Settings ===
embedding:
  # Set via LYRA_ML__EMBEDDING_MODEL in .env (Single Source of Truth)
  # model_name: "BAAI/bge-m3"
  onnx_path: "models/bge-m3"
  batch_size: 8  # Micro-batch for VRAM
  max_length: 512

# === Ranking Settings ===
ranking:
  # Stage 1: BM25
  bm25_top_k: 150  # Top candidates from BM25 for embedding ranking
  
  # Stage 2: Embedding
  embedding_weight: 0.7
  bm25_weight: 0.3
  
  # Dynamic cutoff (Stage 3: replaces Reranker)
  kneedle_cutoff:
    enabled: true
    min_results: 3
    max_results: 50
    sensitivity: 1.0  # Kneedle S parameter

# === NLI Settings ===
# Model name set via LYRA_ML__NLI_MODEL in .env (Single Source of Truth)
# nli section removed - defaults from NLIConfig will be used

# === Storage Settings ===
storage:
  database_path: "data/lyra.db"
  warc_dir: "data/warc"
  screenshots_dir: "data/screenshots"
  reports_dir: "data/reports"
  cache_dir: "data/cache"
  
  # Cache TTL (hours)
  serp_cache_ttl: 24
  fetch_cache_ttl: 168  # 7 days
  embed_cache_ttl: 168  # 7 days

# === Notification Settings ===
notification:
  # Windows toast notification via PowerShell
  windows_toast_enabled: true
  # Linux notify-send
  linux_notify_enabled: true
  # Note: intervention_timeout removed per §3.6.1 (user-driven completion, no timeout)

# === Quality Thresholds ===
quality:
  min_confidence_score: 0.70
  min_independent_sources: 3
  min_primary_sources: 1
  min_secondary_sources: 1
  
  # Source hierarchy weights
  source_weights:
    primary: 1.0      # Primary sources
    government: 0.95  # Government/official
    academic: 0.90    # Academic
    trusted_media: 0.75
    blog: 0.50
    unknown: 0.30

# === Circuit Breaker Settings ===
circuit_breaker:
  # Consecutive failures to open
  failure_threshold: 2
  # Cooldown time (minutes)
  cooldown_min: 30
  cooldown_max: 120
  # Half-open probe interval
  probe_interval: 60

# === Metrics & Adaptation ===
metrics:
  # EMA update interval (seconds)
  ema_update_interval: 60
  # Short-term EMA (1 hour equivalent)
  ema_short_alpha: 0.1
  # Long-term EMA (24 hour equivalent)
  ema_long_alpha: 0.01
  # Hysteresis to prevent oscillation
  hysteresis_min_interval: 300  # 5 minutes

# === Concurrency Settings (ADR-0013/ADR-0014) ===
concurrency:
  # Target queue worker settings
  target_queue:
    # Number of parallel target queue workers (ADR-0010)
    # Min: 1, Default: 2
    num_workers: 2
  
  # Browser SERP tab pool settings
  browser_serp:
    # Maximum concurrent browser tabs for SERP fetching (ADR-0014)
    # Validated safe at 2 tabs; increase cautiously if needed
    # Min: 1, Default: 2
    max_tabs: 2
  
  # Auto-backoff settings (ADR-0013/ADR-0014)
  # Automatically reduce concurrency on errors; recovery varies by resource type
  backoff:
    academic_api:
      # Seconds of stability before attempting to increase max_parallel
      recovery_stable_seconds: 60
      # Amount to decrease max_parallel on 429 error
      decrease_step: 1
    browser_serp:
      # Amount to decrease max_tabs on CAPTCHA/403 detection
      decrease_step: 1
      # Note: No auto_increase for browser SERP (manual only per ADR-0014)

